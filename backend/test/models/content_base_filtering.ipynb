{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMPAqqfDgpfH+xX/yGin1Sc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R3esWA0NHbLP","executionInfo":{"status":"ok","timestamp":1754278245803,"user_tz":-420,"elapsed":1678,"user":{"displayName":"Le Nguyen Thai Tuan B2113346","userId":"03563100155966040964"}},"outputId":"3cf8eb03-6b31-48f6-e10e-1b42e1d59c07"},"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ ƒê√£ import th√†nh c√¥ng!\n"]}],"source":["# Cell 1: Import c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt (ƒë∆°n gi·∫£n)\n","\n","import pandas as pd\n","import numpy as np\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","print(\"‚úÖ ƒê√£ import th√†nh c√¥ng!\")"]},{"cell_type":"code","source":["# Cell 2: K·∫øt n·ªëi Google Drive v√† ƒë·ªçc d·ªØ li·ªáu\n","\n","# K·∫øt n·ªëi Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","print(\"‚úÖ ƒê√£ k·∫øt n·ªëi Google Drive th√†nh c√¥ng!\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WYtut--HIjEZ","executionInfo":{"status":"ok","timestamp":1754278310898,"user_tz":-420,"elapsed":21153,"user":{"displayName":"Le Nguyen Thai Tuan B2113346","userId":"03563100155966040964"}},"outputId":"3d981853-c4bf-4bce-8f8b-69c28f93c470"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","‚úÖ ƒê√£ k·∫øt n·ªëi Google Drive th√†nh c√¥ng!\n"]}]},{"cell_type":"code","source":["# ƒê·ªçc file d·ªØ li·ªáu\n","file_path = '/content/drive/MyDrive/Ebooks/content_base_filtering.csv'\n","df = pd.read_csv(file_path)\n","\n","# Ki·ªÉm tra d·ªØ li·ªáu c∆° b·∫£n\n","print(f\"üìä K√≠ch th∆∞·ªõc d·ªØ li·ªáu: {df.shape}\")\n","print(f\"üìö S·ªë l∆∞·ª£ng s√°ch: {len(df)} cu·ªën\")\n","print(\"\\nüîç 5 d√≤ng ƒë·∫ßu ti√™n:\")\n","print(df.head())\n","\n","print(\"\\nüìã Th√¥ng tin c√°c c·ªôt:\")\n","print(df.info())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VLYsePAzIkOX","executionInfo":{"status":"ok","timestamp":1754278318698,"user_tz":-420,"elapsed":3067,"user":{"displayName":"Le Nguyen Thai Tuan B2113346","userId":"03563100155966040964"}},"outputId":"5a0ac597-9463-407d-f1fd-9a59be3f8912"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["üìä K√≠ch th∆∞·ªõc d·ªØ li·ªáu: (17497, 8)\n","üìö S·ªë l∆∞·ª£ng s√°ch: 17497 cu·ªën\n","\n","üîç 5 d√≤ng ƒë·∫ßu ti√™n:\n","                    user_id                   book_id  rating  \\\n","0  688f391ca18786574ae52478  6887514a9e6faeb381cc3a43       4   \n","1  688f391ca18786574ae52478  68859b92dbd88552ae1fe3f5       4   \n","2  688f391ca18786574ae52478  68886c8a4059e42f0320e856       4   \n","3  688f391ca18786574ae52478  6884b3db381cc6a0ba8b7e90       1   \n","4  688f391ca18786574ae52478  68886a694059e42f0320e7fd       4   \n","\n","               user_faculty                             book_title  \\\n","0  Khoa C√¥ng ngh·ªá Th√¥ng tin  S√°ng t·∫°o b·ª´ng ch√°y s·ª©c m·∫°nh b√™n trong   \n","1  Khoa C√¥ng ngh·ªá Th√¥ng tin              Phong c√°ch h·ªçc ti·∫øng Vi·ªát   \n","2  Khoa C√¥ng ngh·ªá Th√¥ng tin                        Tr√≠ tu·ªá Do Th√°i   \n","3  Khoa C√¥ng ngh·ªá Th√¥ng tin           Khai th√°c d·ªØ li·ªáu v·ªõi Python   \n","4  Khoa C√¥ng ngh·ªá Th√¥ng tin            N·ªÅn gi√°o d·ª•c c·ªßa ng∆∞·ªùi gi√†u   \n","\n","                                    book_description        book_category  \\\n","0  S√°ng T·∫°o ‚Äì B·ª´ng Ch√°y S·ª©c M·∫°nh B√™n Trong l√† m·ªôt...            Tri·∫øt h·ªçc   \n","1  Gi√°o tr√¨nh n√†y bi√™n so·∫°n nh·∫±m m·ª•c ƒë√≠ch cung c·∫•...             Gi√°o d·ª•c   \n","2  Tr√≠ Tu·ªá Do Th√°i c·ªßa Eran Katz l√† m·ªôt cu·ªën s√°ch...              Kinh t·∫ø   \n","3  Nh·∫±m g√≥p ph·∫ßn l√†m phong ph√∫ ngu·ªìn t∆∞ li·ªáu ph·ª•c...  C√¥ng ngh·ªá th√¥ng tin   \n","4  N·ªÅn Gi√°o D·ª•c C·ªßa Ng∆∞·ªùi Gi√†u c·ªßa Michael Ellsbe...              Kinh t·∫ø   \n","\n","  book_document_type  \n","0              other  \n","1           textbook  \n","2              other  \n","3           textbook  \n","4              other  \n","\n","üìã Th√¥ng tin c√°c c·ªôt:\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 17497 entries, 0 to 17496\n","Data columns (total 8 columns):\n"," #   Column              Non-Null Count  Dtype \n","---  ------              --------------  ----- \n"," 0   user_id             17497 non-null  object\n"," 1   book_id             17497 non-null  object\n"," 2   rating              17497 non-null  int64 \n"," 3   user_faculty        17497 non-null  object\n"," 4   book_title          17497 non-null  object\n"," 5   book_description    17497 non-null  object\n"," 6   book_category       17497 non-null  object\n"," 7   book_document_type  17497 non-null  object\n","dtypes: int64(1), object(7)\n","memory usage: 1.1+ MB\n","None\n"]}]},{"cell_type":"code","source":["# Cell 3: Chu·∫©n b·ªã d·ªØ li·ªáu cho Content-Based Filtering (ƒë√£ s·ª≠a)\n","\n","print(\"üîß CHU·∫®N B·ªä D·ªÆ LI·ªÜU\")\n","print(\"=\"*50)\n","\n","# 1. Drop c·ªôt rating (ƒë∆°n gi·∫£n h√≥a)\n","df_clean = df.drop(columns=['rating'])\n","print(\"‚úÖ ƒê√£ lo·∫°i b·ªè c·ªôt rating\")\n","\n","# 2. X√≥a t·∫•t c·∫£ d√≤ng c·ªßa user c·ª• th·ªÉ\n","user_to_remove = \"688c54f1b80dd6dd7a0afed0\"\n","before_count = len(df_clean)\n","df_clean = df_clean[df_clean['user_id'] != user_to_remove]\n","after_count = len(df_clean)\n","removed_count = before_count - after_count\n","\n","print(f\"üóëÔ∏è ƒê√£ x√≥a {removed_count} d√≤ng c·ªßa user: {user_to_remove}\")\n","print(f\"üìä D·ªØ li·ªáu c√≤n l·∫°i: {after_count} d√≤ng\")\n","\n","# 3. T·∫°o dataset s√°ch duy nh·∫•t (lo·∫°i b·ªè duplicate)\n","books_df = df_clean.drop_duplicates(subset=['book_id']).reset_index(drop=True)\n","print(f\"\\nüìö Dataset s√°ch duy nh·∫•t: {len(books_df)} cu·ªën\")\n","\n","# 4. Hi·ªÉn th·ªã m·∫´u d·ªØ li·ªáu ƒë√£ clean\n","print(f\"\\nüîç C·∫•u tr√∫c d·ªØ li·ªáu sau khi clean:\")\n","print(books_df.columns.tolist())\n","print(f\"\\nüìã M·∫´u d·ªØ li·ªáu:\")\n","print(books_df[['book_title', 'book_category', 'book_document_type']].head())\n","\n","# 5. Ki·ªÉm tra user c√≤n l·∫°i\n","remaining_users = df_clean['user_id'].nunique()\n","print(f\"\\nüë• S·ªë user c√≤n l·∫°i: {remaining_users}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8x27Z-MTI3gW","executionInfo":{"status":"ok","timestamp":1754278933394,"user_tz":-420,"elapsed":67,"user":{"displayName":"Le Nguyen Thai Tuan B2113346","userId":"03563100155966040964"}},"outputId":"6f1689de-cc52-41f1-9d74-619884068fef"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["üîß CHU·∫®N B·ªä D·ªÆ LI·ªÜU\n","==================================================\n","‚úÖ ƒê√£ lo·∫°i b·ªè c·ªôt rating\n","üóëÔ∏è ƒê√£ x√≥a 1 d√≤ng c·ªßa user: 688c54f1b80dd6dd7a0afed0\n","üìä D·ªØ li·ªáu c√≤n l·∫°i: 17496 d√≤ng\n","\n","üìö Dataset s√°ch duy nh·∫•t: 120 cu·ªën\n","\n","üîç C·∫•u tr√∫c d·ªØ li·ªáu sau khi clean:\n","['user_id', 'book_id', 'user_faculty', 'book_title', 'book_description', 'book_category', 'book_document_type']\n","\n","üìã M·∫´u d·ªØ li·ªáu:\n","                              book_title        book_category  \\\n","0  S√°ng t·∫°o b·ª´ng ch√°y s·ª©c m·∫°nh b√™n trong            Tri·∫øt h·ªçc   \n","1              Phong c√°ch h·ªçc ti·∫øng Vi·ªát             Gi√°o d·ª•c   \n","2                        Tr√≠ tu·ªá Do Th√°i              Kinh t·∫ø   \n","3           Khai th√°c d·ªØ li·ªáu v·ªõi Python  C√¥ng ngh·ªá th√¥ng tin   \n","4            N·ªÅn gi√°o d·ª•c c·ªßa ng∆∞·ªùi gi√†u              Kinh t·∫ø   \n","\n","  book_document_type  \n","0              other  \n","1           textbook  \n","2              other  \n","3           textbook  \n","4              other  \n","\n","üë• S·ªë user c√≤n l·∫°i: 940\n"]}]},{"cell_type":"code","source":["# Cell 4: Ti·ªÅn x·ª≠ l√Ω text ti·∫øng Vi·ªát\n","import re\n","import string\n","\n","def clean_vietnamese_text(text):\n","    \"\"\"\n","    H√†m l√†m s·∫°ch text ti·∫øng Vi·ªát\n","    - Gi·ªØ nguy√™n d·∫•u ti·∫øng Vi·ªát\n","    - Lo·∫°i b·ªè k√≠ t·ª± ƒë·∫∑c bi·ªát\n","    - Chu·∫©n h√≥a kho·∫£ng tr·∫Øng\n","    \"\"\"\n","    if pd.isna(text) or text == \"\":\n","        return \"\"\n","\n","    # Chuy·ªÉn v·ªÅ ch·ªØ th∆∞·ªùng\n","    text = text.lower()\n","\n","    # Lo·∫°i b·ªè c√°c k√≠ t·ª± ƒë·∫∑c bi·ªát (gi·ªØ l·∫°i ch·ªØ, s·ªë, space)\n","    # Gi·ªØ l·∫°i: a-z, A-Z, 0-9, space, v√† c√°c k√≠ t·ª± ti·∫øng Vi·ªát c√≥ d·∫•u\n","    text = re.sub(r'[^\\w\\s]', ' ', text)\n","\n","    # Lo·∫°i b·ªè kho·∫£ng tr·∫Øng th·ª´a\n","    text = re.sub(r'\\s+', ' ', text)\n","\n","    # Lo·∫°i b·ªè kho·∫£ng tr·∫Øng ·ªü ƒë·∫ßu v√† cu·ªëi\n","    text = text.strip()\n","\n","    return text\n","\n","print(\"üßπ TI·ªÄN X·ª¨ L√ù TEXT TI·∫æNG VI·ªÜT\")\n","print(\"=\"*50)\n","\n","# Test h√†m clean v·ªõi v√†i v√≠ d·ª•\n","test_texts = [\n","    \"Khai th√°c d·ªØ li·ªáu v·ªõi Python - Machine Learning\",\n","    \"Tri·∫øt h·ªçc & ƒê·∫°o ƒë·ª©c kinh doanh (2023)\",\n","    \"C√¥ng ngh·ªá th√¥ng tin!!! C∆° s·ªü d·ªØ li·ªáu???\"\n","]\n","\n","print(\"üîç TEST H√ÄM CLEAN TEXT:\")\n","for original in test_texts:\n","    cleaned = clean_vietnamese_text(original)\n","    print(f\"G·ªëc:     {original}\")\n","    print(f\"Cleaned: {cleaned}\")\n","    print(\"-\" * 40)\n","\n","# √Åp d·ª•ng cho dataset s√°ch\n","print(\"üìö √ÅP D·ª§NG CHO DATASET S√ÅCH:\")\n","print(\"ƒêang x·ª≠ l√Ω title v√† description...\")\n","\n","# Clean title\n","books_df['title_clean'] = books_df['book_title'].apply(clean_vietnamese_text)\n","\n","# Clean description\n","books_df['description_clean'] = books_df['book_description'].apply(clean_vietnamese_text)\n","\n","print(\"‚úÖ Ho√†n th√†nh ti·ªÅn x·ª≠ l√Ω!\")\n","print(f\"üìä S·ªë s√°ch ƒë√£ x·ª≠ l√Ω: {len(books_df)}\")\n","\n","# Hi·ªÉn th·ªã k·∫øt qu·∫£ m·∫´u\n","print(\"\\nüìã V√ç D·ª§ K·∫æT QU·∫¢:\")\n","sample_df = books_df[['book_title', 'title_clean', 'book_description', 'description_clean']].head(3)\n","for idx, row in sample_df.iterrows():\n","    print(f\"\\nüìñ S√°ch {idx+1}:\")\n","    print(f\"Title g·ªëc: {row['book_title']}\")\n","    print(f\"Title clean: {row['title_clean']}\")\n","    print(f\"Description g·ªëc: {row['book_description'][:100]}...\")\n","    print(f\"Description clean: {row['description_clean'][:100]}...\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6I9XqPxjMznG","executionInfo":{"status":"ok","timestamp":1754279395598,"user_tz":-420,"elapsed":72,"user":{"displayName":"Le Nguyen Thai Tuan B2113346","userId":"03563100155966040964"}},"outputId":"a7dca18e-b880-4a8a-c396-829a3144228a"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["üßπ TI·ªÄN X·ª¨ L√ù TEXT TI·∫æNG VI·ªÜT\n","==================================================\n","üîç TEST H√ÄM CLEAN TEXT:\n","G·ªëc:     Khai th√°c d·ªØ li·ªáu v·ªõi Python - Machine Learning\n","Cleaned: khai th√°c d·ªØ li·ªáu v·ªõi python machine learning\n","----------------------------------------\n","G·ªëc:     Tri·∫øt h·ªçc & ƒê·∫°o ƒë·ª©c kinh doanh (2023)\n","Cleaned: tri·∫øt h·ªçc ƒë·∫°o ƒë·ª©c kinh doanh 2023\n","----------------------------------------\n","G·ªëc:     C√¥ng ngh·ªá th√¥ng tin!!! C∆° s·ªü d·ªØ li·ªáu???\n","Cleaned: c√¥ng ngh·ªá th√¥ng tin c∆° s·ªü d·ªØ li·ªáu\n","----------------------------------------\n","üìö √ÅP D·ª§NG CHO DATASET S√ÅCH:\n","ƒêang x·ª≠ l√Ω title v√† description...\n","‚úÖ Ho√†n th√†nh ti·ªÅn x·ª≠ l√Ω!\n","üìä S·ªë s√°ch ƒë√£ x·ª≠ l√Ω: 120\n","\n","üìã V√ç D·ª§ K·∫æT QU·∫¢:\n","\n","üìñ S√°ch 1:\n","Title g·ªëc: S√°ng t·∫°o b·ª´ng ch√°y s·ª©c m·∫°nh b√™n trong\n","Title clean: s√°ng t·∫°o b·ª´ng ch√°y s·ª©c m·∫°nh b√™n trong\n","Description g·ªëc: S√°ng T·∫°o ‚Äì B·ª´ng Ch√°y S·ª©c M·∫°nh B√™n Trong l√† m·ªôt trong nh·ªØng t√°c ph·∫©m gi√†u c·∫£m h·ª©ng nh·∫•t c·ªßa Osho, b·∫≠c...\n","Description clean: s√°ng t·∫°o b·ª´ng ch√°y s·ª©c m·∫°nh b√™n trong l√† m·ªôt trong nh·ªØng t√°c ph·∫©m gi√†u c·∫£m h·ª©ng nh·∫•t c·ªßa osho b·∫≠c th...\n","\n","üìñ S√°ch 2:\n","Title g·ªëc: Phong c√°ch h·ªçc ti·∫øng Vi·ªát\n","Title clean: phong c√°ch h·ªçc ti·∫øng vi·ªát\n","Description g·ªëc: Gi√°o tr√¨nh n√†y bi√™n so·∫°n nh·∫±m m·ª•c ƒë√≠ch cung c·∫•p cho sinh vi√™n ng√†nh s∆∞ ph·∫°m Ng·ªØ vƒÉn, ng√†nh Ng√¥n ng·ªØ ...\n","Description clean: gi√°o tr√¨nh n√†y bi√™n so·∫°n nh·∫±m m·ª•c ƒë√≠ch cung c·∫•p cho sinh vi√™n ng√†nh s∆∞ ph·∫°m ng·ªØ vƒÉn ng√†nh ng√¥n ng·ªØ v...\n","\n","üìñ S√°ch 3:\n","Title g·ªëc: Tr√≠ tu·ªá Do Th√°i\n","Title clean: tr√≠ tu·ªá do th√°i\n","Description g·ªëc: Tr√≠ Tu·ªá Do Th√°i c·ªßa Eran Katz l√† m·ªôt cu·ªën s√°ch khai m·ªü nh·ªØng b√†i h·ªçc qu√Ω gi√° t·ª´ n·ªÅn vƒÉn h√≥a Do Th√°i ...\n","Description clean: tr√≠ tu·ªá do th√°i c·ªßa eran katz l√† m·ªôt cu·ªën s√°ch khai m·ªü nh·ªØng b√†i h·ªçc qu√Ω gi√° t·ª´ n·ªÅn vƒÉn h√≥a do th√°i ...\n"]}]},{"cell_type":"code","source":["# Cell 5: T·∫°o TF-IDF vectors cho Title v√† Description\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","import numpy as np\n","\n","print(\"üî¢ T·∫†O TF-IDF VECTORS\")\n","print(\"=\"*50)\n","\n","# Danh s√°ch stopwords ti·∫øng Vi·ªát c∆° b·∫£n\n","vietnamese_stopwords = [\n","    'c·ªßa', 'v√†', 'v·ªõi', 'trong', 't·ª´', 'cho', 'v·ªÅ', 'l√†', 'c√≥', 'ƒë∆∞·ª£c',\n","    'c√°c', 'm·ªôt', 'ƒë·ªÉ', 'nh∆∞', 'nh·ªØng', 'n√†y', 'ƒë√≥', 'khi', 'n·∫øu', 'theo',\n","    'ho·∫∑c', 'nh∆∞ng', 'm√†', 'th√¨', 's·∫Ω', 'ƒë√£', 'hay', 'c√≤n', 'ch·ªâ', 'c≈©ng'\n","]\n","\n","print(f\"üìù S·ª≠ d·ª•ng {len(vietnamese_stopwords)} stopwords ti·∫øng Vi·ªát\")\n","\n","# 1. TF-IDF cho Title\n","print(\"\\nüìñ T·∫†O TF-IDF CHO TITLE:\")\n","title_vectorizer = TfidfVectorizer(\n","    max_features=1000,        # Gi·ªõi h·∫°n 1000 t·ª´ quan tr·ªçng nh·∫•t\n","    stop_words=vietnamese_stopwords,\n","    ngram_range=(1, 2),       # Unigram v√† bigram\n","    min_df=2,                 # T·ª´ ph·∫£i xu·∫•t hi·ªán √≠t nh·∫•t 2 l·∫ßn\n","    max_df=0.8               # Lo·∫°i b·ªè t·ª´ xu·∫•t hi·ªán qu√° 80% documents\n",")\n","\n","title_tfidf_matrix = title_vectorizer.fit_transform(books_df['title_clean'])\n","print(f\"‚úÖ Title TF-IDF shape: {title_tfidf_matrix.shape}\")\n","print(f\"üìä S·ªë t·ª´ trong vocabulary: {len(title_vectorizer.vocabulary_)}\")\n","\n","# 2. TF-IDF cho Description\n","print(\"\\nüìÑ T·∫†O TF-IDF CHO DESCRIPTION:\")\n","desc_vectorizer = TfidfVectorizer(\n","    max_features=2000,        # Description d√†i h∆°n n√™n cho nhi·ªÅu features h∆°n\n","    stop_words=vietnamese_stopwords,\n","    ngram_range=(1, 2),\n","    min_df=2,\n","    max_df=0.8\n",")\n","\n","desc_tfidf_matrix = desc_vectorizer.fit_transform(books_df['description_clean'])\n","print(f\"‚úÖ Description TF-IDF shape: {desc_tfidf_matrix.shape}\")\n","print(f\"üìä S·ªë t·ª´ trong vocabulary: {len(desc_vectorizer.vocabulary_)}\")\n","\n","# 3. Hi·ªÉn th·ªã top keywords\n","print(\"\\nüîç TOP 10 T·ª™ KH√ìA QUAN TR·ªåNG:\")\n","print(\"\\nüìñ Title keywords:\")\n","title_feature_names = title_vectorizer.get_feature_names_out()\n","title_scores = np.array(title_tfidf_matrix.sum(axis=0)).flatten()\n","title_top_indices = title_scores.argsort()[-10:][::-1]\n","for i, idx in enumerate(title_top_indices):\n","    print(f\"  {i+1}. {title_feature_names[idx]} (score: {title_scores[idx]:.2f})\")\n","\n","print(\"\\nüìÑ Description keywords:\")\n","desc_feature_names = desc_vectorizer.get_feature_names_out()\n","desc_scores = np.array(desc_tfidf_matrix.sum(axis=0)).flatten()\n","desc_top_indices = desc_scores.argsort()[-10:][::-1]\n","for i, idx in enumerate(desc_top_indices):\n","    print(f\"  {i+1}. {desc_feature_names[idx]} (score: {desc_scores[idx]:.2f})\")\n","\n","# 4. L∆∞u k·∫øt qu·∫£ ƒë·ªÉ s·ª≠ d·ª•ng ·ªü cell ti·∫øp theo\n","print(f\"\\nüíæ ƒê√É T·∫†O XONG TF-IDF VECTORS!\")\n","print(f\"üìè T·ªïng dimensions: Title({title_tfidf_matrix.shape[1]}) + Description({desc_tfidf_matrix.shape[1]})\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AMdHRR7jNLL9","executionInfo":{"status":"ok","timestamp":1754279498644,"user_tz":-420,"elapsed":197,"user":{"displayName":"Le Nguyen Thai Tuan B2113346","userId":"03563100155966040964"}},"outputId":"fb1c8187-a3eb-4455-bece-8f1f02fce6f1"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["üî¢ T·∫†O TF-IDF VECTORS\n","==================================================\n","üìù S·ª≠ d·ª•ng 30 stopwords ti·∫øng Vi·ªát\n","\n","üìñ T·∫†O TF-IDF CHO TITLE:\n","‚úÖ Title TF-IDF shape: (120, 202)\n","üìä S·ªë t·ª´ trong vocabulary: 202\n","\n","üìÑ T·∫†O TF-IDF CHO DESCRIPTION:\n","‚úÖ Description TF-IDF shape: (120, 2000)\n","üìä S·ªë t·ª´ trong vocabulary: 2000\n","\n","üîç TOP 10 T·ª™ KH√ìA QUAN TR·ªåNG:\n","\n","üìñ Title keywords:\n","  1. h·ªçc (score: 5.92)\n","  2. tr√¨nh (score: 3.69)\n","  3. l√Ω (score: 3.62)\n","  4. thu·∫≠t (score: 3.43)\n","  5. l·∫≠p (score: 3.34)\n","  6. l·∫≠p tr√¨nh (score: 3.34)\n","  7. c√¥ng (score: 3.03)\n","  8. k·ªπ (score: 2.93)\n","  9. k·ªπ thu·∫≠t (score: 2.93)\n","  10. s·∫£n (score: 2.87)\n","\n","üìÑ Description keywords:\n","  1. kh√¥ng (score: 5.38)\n","  2. gi√°o (score: 5.30)\n","  3. ch∆∞∆°ng (score: 5.18)\n","  4. gi√°o tr√¨nh (score: 4.86)\n","  5. s·∫£n (score: 4.41)\n","  6. c√¥ng (score: 3.99)\n","  7. sinh (score: 3.88)\n","  8. th·ª±c (score: 3.75)\n","  9. l√Ω (score: 3.68)\n","  10. li·ªáu (score: 3.58)\n","\n","üíæ ƒê√É T·∫†O XONG TF-IDF VECTORS!\n","üìè T·ªïng dimensions: Title(202) + Description(2000)\n"]}]},{"cell_type":"code","source":["# Cell 6: One-Hot Encoding cho Category v√† Document Type\n","from sklearn.preprocessing import OneHotEncoder\n","import pandas as pd\n","\n","print(\"üè∑Ô∏è ONE-HOT ENCODING CHO CATEGORICAL FEATURES\")\n","print(\"=\"*50)\n","\n","# 1. Ph√¢n t√≠ch categories v√† document types\n","print(\"üìä PH√ÇN T√çCH D·ªÆ LI·ªÜU CATEGORICAL:\")\n","print(f\"\\nüìö C√°c th·ªÉ lo·∫°i s√°ch (Categories):\")\n","categories = books_df['book_category'].value_counts()\n","print(categories)\n","\n","print(f\"\\nüìÑ C√°c lo·∫°i t√†i li·ªáu (Document Types):\")\n","doc_types = books_df['book_document_type'].value_counts()\n","print(doc_types)\n","\n","# 2. One-Hot Encoding cho Category\n","print(f\"\\nüîÑ TH·ª∞C HI·ªÜN ONE-HOT ENCODING:\")\n","category_encoder = OneHotEncoder(sparse_output=False, dtype=int)\n","category_encoded = category_encoder.fit_transform(books_df[['book_category']])\n","\n","print(f\"‚úÖ Category encoding shape: {category_encoded.shape}\")\n","print(f\"üìã Category labels: {list(category_encoder.categories_[0])}\")\n","\n","# 3. One-Hot Encoding cho Document Type\n","doc_type_encoder = OneHotEncoder(sparse_output=False, dtype=int)\n","doc_type_encoded = doc_type_encoder.fit_transform(books_df[['book_document_type']])\n","\n","print(f\"‚úÖ Document type encoding shape: {doc_type_encoded.shape}\")\n","print(f\"üìã Document type labels: {list(doc_type_encoder.categories_[0])}\")\n","\n","# 4. T·∫°o DataFrame ƒë·ªÉ d·ªÖ hi·ªÉu\n","print(f\"\\nüìã V√ç D·ª§ ENCODING RESULTS:\")\n","\n","# Category DataFrame\n","category_df = pd.DataFrame(\n","    category_encoded,\n","    columns=[f\"category_{cat}\" for cat in category_encoder.categories_[0]]\n",")\n","print(f\"\\nüè∑Ô∏è Category One-Hot (5 s√°ch ƒë·∫ßu):\")\n","print(category_df.head())\n","\n","# Document Type DataFrame\n","doc_type_df = pd.DataFrame(\n","    doc_type_encoded,\n","    columns=[f\"doctype_{dtype}\" for dtype in doc_type_encoder.categories_[0]]\n",")\n","print(f\"\\nüìÑ Document Type One-Hot (5 s√°ch ƒë·∫ßu):\")\n","print(doc_type_df.head())\n","\n","# 5. K·∫øt h·ª£p v·ªõi th√¥ng tin s√°ch ƒë·ªÉ ki·ªÉm tra\n","print(f\"\\nüîç KI·ªÇM TRA K·∫æT QU·∫¢ ENCODING:\")\n","check_df = pd.concat([\n","    books_df[['book_title', 'book_category', 'book_document_type']].head(),\n","    category_df.head(),\n","    doc_type_df.head()\n","], axis=1)\n","\n","for idx in range(3):\n","    print(f\"\\nüìñ S√°ch {idx+1}: {check_df.iloc[idx]['book_title']}\")\n","    print(f\"   Category: {check_df.iloc[idx]['book_category']}\")\n","    print(f\"   Doc Type: {check_df.iloc[idx]['book_document_type']}\")\n","\n","    # Hi·ªÉn th·ªã which categories = 1\n","    cat_cols = [col for col in check_df.columns if col.startswith('category_')]\n","    active_cats = [col.replace('category_', '') for col in cat_cols if check_df.iloc[idx][col] == 1]\n","    print(f\"   Category encoding: {active_cats}\")\n","\n","    # Hi·ªÉn th·ªã which doc types = 1\n","    doc_cols = [col for col in check_df.columns if col.startswith('doctype_')]\n","    active_docs = [col.replace('doctype_', '') for col in doc_cols if check_df.iloc[idx][col] == 1]\n","    print(f\"   DocType encoding: {active_docs}\")\n","\n","print(f\"\\nüíæ HO√ÄN TH√ÄNH ONE-HOT ENCODING!\")\n","print(f\"üìè T·ªïng categorical dimensions: {category_encoded.shape[1] + doc_type_encoded.shape[1]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vymd2g7gOQwt","executionInfo":{"status":"ok","timestamp":1754279778556,"user_tz":-420,"elapsed":210,"user":{"displayName":"Le Nguyen Thai Tuan B2113346","userId":"03563100155966040964"}},"outputId":"c114dbd0-a8f9-4789-be00-d7c820c261cd"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["üè∑Ô∏è ONE-HOT ENCODING CHO CATEGORICAL FEATURES\n","==================================================\n","üìä PH√ÇN T√çCH D·ªÆ LI·ªÜU CATEGORICAL:\n","\n","üìö C√°c th·ªÉ lo·∫°i s√°ch (Categories):\n","book_category\n","Khoa h·ªçc t·ª± nhi√™n      38\n","C√¥ng ngh·ªá th√¥ng tin    28\n","VƒÉn h·ªçc                19\n","Tri·∫øt h·ªçc              13\n","Kinh t·∫ø                13\n","Gi√°o d·ª•c                9\n","Name: count, dtype: int64\n","\n","üìÑ C√°c lo·∫°i t√†i li·ªáu (Document Types):\n","book_document_type\n","other       64\n","textbook    56\n","Name: count, dtype: int64\n","\n","üîÑ TH·ª∞C HI·ªÜN ONE-HOT ENCODING:\n","‚úÖ Category encoding shape: (120, 6)\n","üìã Category labels: ['C√¥ng ngh·ªá th√¥ng tin', 'Gi√°o d·ª•c', 'Khoa h·ªçc t·ª± nhi√™n', 'Kinh t·∫ø', 'Tri·∫øt h·ªçc', 'VƒÉn h·ªçc']\n","‚úÖ Document type encoding shape: (120, 2)\n","üìã Document type labels: ['other', 'textbook']\n","\n","üìã V√ç D·ª§ ENCODING RESULTS:\n","\n","üè∑Ô∏è Category One-Hot (5 s√°ch ƒë·∫ßu):\n","   category_C√¥ng ngh·ªá th√¥ng tin  category_Gi√°o d·ª•c  \\\n","0                             0                  0   \n","1                             0                  1   \n","2                             0                  0   \n","3                             1                  0   \n","4                             0                  0   \n","\n","   category_Khoa h·ªçc t·ª± nhi√™n  category_Kinh t·∫ø  category_Tri·∫øt h·ªçc  \\\n","0                           0                 0                   1   \n","1                           0                 0                   0   \n","2                           0                 1                   0   \n","3                           0                 0                   0   \n","4                           0                 1                   0   \n","\n","   category_VƒÉn h·ªçc  \n","0                 0  \n","1                 0  \n","2                 0  \n","3                 0  \n","4                 0  \n","\n","üìÑ Document Type One-Hot (5 s√°ch ƒë·∫ßu):\n","   doctype_other  doctype_textbook\n","0              1                 0\n","1              0                 1\n","2              1                 0\n","3              0                 1\n","4              1                 0\n","\n","üîç KI·ªÇM TRA K·∫æT QU·∫¢ ENCODING:\n","\n","üìñ S√°ch 1: S√°ng t·∫°o b·ª´ng ch√°y s·ª©c m·∫°nh b√™n trong\n","   Category: Tri·∫øt h·ªçc\n","   Doc Type: other\n","   Category encoding: ['Tri·∫øt h·ªçc']\n","   DocType encoding: ['other']\n","\n","üìñ S√°ch 2: Phong c√°ch h·ªçc ti·∫øng Vi·ªát\n","   Category: Gi√°o d·ª•c\n","   Doc Type: textbook\n","   Category encoding: ['Gi√°o d·ª•c']\n","   DocType encoding: ['textbook']\n","\n","üìñ S√°ch 3: Tr√≠ tu·ªá Do Th√°i\n","   Category: Kinh t·∫ø\n","   Doc Type: other\n","   Category encoding: ['Kinh t·∫ø']\n","   DocType encoding: ['other']\n","\n","üíæ HO√ÄN TH√ÄNH ONE-HOT ENCODING!\n","üìè T·ªïng categorical dimensions: 8\n"]}]},{"cell_type":"markdown","source":["- Title TF-IDF: 202 dimensions\n","- Description TF-IDF: 2000 dimensions  \n","- Category OneHot: 6 dimensions\n","- DocType OneHot: 2 dimensions\n","---\n","T·ªîNG: 2210 dimensions"],"metadata":{"id":"-DZMvWAvOrQn"}},{"cell_type":"code","source":["# Cell 7: K·∫øt h·ª£p t·∫•t c·∫£ features v·ªõi tr·ªçng s·ªë (Updated)\n","import numpy as np\n","from sklearn.preprocessing import normalize\n","from scipy import sparse\n","\n","print(\"‚öñÔ∏è K·∫æT H·ª¢P T·∫§T C·∫¢ FEATURES V·ªöI TR·ªåNG S·ªê (UPDATED)\")\n","print(\"=\"*50)\n","\n","# ƒê·ªãnh nghƒ©a tr·ªçng s·ªë m·ªõi: tƒÉng category, gi·∫£m description\n","weights = {\n","    'title': 0.25,\n","    'description': 0.3,    # Gi·∫£m t·ª´ 0.4 ‚Üí 0.3 (-0.1)\n","    'category': 0.35,      # TƒÉng t·ª´ 0.25 ‚Üí 0.35 (+0.1)\n","    'doc_type': 0.1\n","}\n","\n","print(\"üìä TR·ªåNG S·ªê M·ªöI (category cao h∆°n):\")\n","for feature, weight in weights.items():\n","    print(f\"   {feature}: {weight}\")\n","\n","# Ki·ªÉm tra t·ªïng tr·ªçng s·ªë = 1\n","total_weight = sum(weights.values())\n","print(f\"‚úÖ T·ªïng tr·ªçng s·ªë: {total_weight}\")\n","\n","print(f\"\\nüìè K√çCH TH∆Ø·ªöC C√ÅC FEATURE MATRICES:\")\n","print(f\"   Title TF-IDF: {title_tfidf_matrix.shape}\")\n","print(f\"   Description TF-IDF: {desc_tfidf_matrix.shape}\")\n","print(f\"   Category OneHot: {category_encoded.shape}\")\n","print(f\"   DocType OneHot: {doc_type_encoded.shape}\")\n","\n","# 1. Chu·∫©n h√≥a t·ª´ng feature matrix (L2 normalization)\n","print(f\"\\nüîÑ CHU·∫®N H√ìA C√ÅC FEATURE MATRICES:\")\n","\n","# Normalize TF-IDF matrices (ƒë√£ l√† sparse)\n","title_normalized = normalize(title_tfidf_matrix, norm='l2', axis=1)\n","desc_normalized = normalize(desc_tfidf_matrix, norm='l2', axis=1)\n","\n","# Normalize categorical matrices (dense)\n","category_normalized = normalize(category_encoded, norm='l2', axis=1)\n","doc_type_normalized = normalize(doc_type_encoded, norm='l2', axis=1)\n","\n","print(\"‚úÖ ƒê√£ chu·∫©n h√≥a t·∫•t c·∫£ feature matrices\")\n","\n","# 2. √Åp d·ª•ng tr·ªçng s·ªë m·ªõi v√† k·∫øt h·ª£p\n","print(f\"\\n‚öñÔ∏è √ÅP D·ª§NG TR·ªåNG S·ªê M·ªöI:\")\n","\n","# Apply updated weights\n","title_weighted = title_normalized * weights['title']\n","desc_weighted = desc_normalized * weights['description']  # 0.3\n","category_weighted = category_normalized * weights['category']  # 0.35\n","doc_type_weighted = doc_type_normalized * weights['doc_type']\n","\n","print(\"‚úÖ ƒê√£ √°p d·ª•ng tr·ªçng s·ªë m·ªõi cho t·ª´ng feature\")\n","print(f\"   üìñ Title weight: {weights['title']}\")\n","print(f\"   üìÑ Description weight: {weights['description']} (gi·∫£m)\")\n","print(f\"   üè∑Ô∏è Category weight: {weights['category']} (tƒÉng)\")\n","print(f\"   üìã DocType weight: {weights['doc_type']}\")\n","\n","# 3. K·∫øt h·ª£p t·∫•t c·∫£ features\n","print(f\"\\nüîó K·∫æT H·ª¢P T·∫§T C·∫¢ FEATURES:\")\n","\n","# Convert dense arrays to sparse for efficient concatenation\n","category_sparse = sparse.csr_matrix(category_weighted)\n","doc_type_sparse = sparse.csr_matrix(doc_type_weighted)\n","\n","# Concatenate all features horizontally\n","combined_features = sparse.hstack([\n","    title_weighted,      # 202 dims\n","    desc_weighted,       # 2000 dims\n","    category_sparse,     # 6 dims\n","    doc_type_sparse      # 2 dims\n","])\n","\n","print(f\"‚úÖ Combined features shape: {combined_features.shape}\")\n","print(f\"üìä T·ªïng dimensions: {combined_features.shape[1]}\")\n","\n","# 4. Ki·ªÉm tra impact c·ªßa tr·ªçng s·ªë m·ªõi\n","print(f\"\\nüîç KI·ªÇM TRA T√ÅC ƒê·ªòNG TR·ªåNG S·ªê M·ªöI:\")\n","\n","for i in range(3):\n","    book_title = books_df.iloc[i]['book_title']\n","    book_category = books_df.iloc[i]['book_category']\n","    feature_vector = combined_features[i].toarray().flatten()\n","\n","    # T√≠nh norm c·ªßa t·ª´ng component\n","    title_start, title_end = 0, 202\n","    desc_start, desc_end = 202, 2202\n","    cat_start, cat_end = 2202, 2208\n","    doc_start, doc_end = 2208, 2210\n","\n","    title_norm = np.linalg.norm(feature_vector[title_start:title_end])\n","    desc_norm = np.linalg.norm(feature_vector[desc_start:desc_end])\n","    cat_norm = np.linalg.norm(feature_vector[cat_start:cat_end])\n","    doc_norm = np.linalg.norm(feature_vector[doc_start:doc_end])\n","\n","    print(f\"\\nüìñ S√°ch {i+1}: {book_title}\")\n","    print(f\"   üè∑Ô∏è Category: {book_category}\")\n","    print(f\"   üìñ Title component: {title_norm:.4f}\")\n","    print(f\"   üìÑ Description component: {desc_norm:.4f} (gi·∫£m weight)\")\n","    print(f\"   üè∑Ô∏è Category component: {cat_norm:.4f} (tƒÉng weight)\")\n","    print(f\"   üìã DocType component: {doc_norm:.4f}\")\n","    print(f\"   üéØ Total vector norm: {np.linalg.norm(feature_vector):.4f}\")\n","\n","# 5. L∆∞u th√¥ng tin v·ªõi tr·ªçng s·ªë m·ªõi\n","feature_info = {\n","    'matrix': combined_features,\n","    'dimensions': {\n","        'title': (0, 202),\n","        'description': (202, 2202),\n","        'category': (2202, 2208),\n","        'doc_type': (2208, 2210)\n","    },\n","    'weights': weights,  # Tr·ªçng s·ªë m·ªõi\n","    'total_dims': combined_features.shape[1]\n","}\n","\n","print(f\"\\nüíæ ƒê√É HO√ÄN TH√ÄNH K·∫æT H·ª¢P FEATURES V·ªöI TR·ªåNG S·ªê M·ªöI!\")\n","print(f\"üéØ Category importance tƒÉng l√™n ‚Üí recommendation theo ch·ªß ƒë·ªÅ t·ªët h∆°n!\")\n","print(f\"üìè Final feature matrix: {combined_features.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C5haonpnO5Rt","executionInfo":{"status":"ok","timestamp":1754280055447,"user_tz":-420,"elapsed":68,"user":{"displayName":"Le Nguyen Thai Tuan B2113346","userId":"03563100155966040964"}},"outputId":"e17bf0a4-491b-4aa4-ded8-cbc533c582b7"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["‚öñÔ∏è K·∫æT H·ª¢P T·∫§T C·∫¢ FEATURES V·ªöI TR·ªåNG S·ªê (UPDATED)\n","==================================================\n","üìä TR·ªåNG S·ªê M·ªöI (category cao h∆°n):\n","   title: 0.25\n","   description: 0.3\n","   category: 0.35\n","   doc_type: 0.1\n","‚úÖ T·ªïng tr·ªçng s·ªë: 1.0\n","\n","üìè K√çCH TH∆Ø·ªöC C√ÅC FEATURE MATRICES:\n","   Title TF-IDF: (120, 202)\n","   Description TF-IDF: (120, 2000)\n","   Category OneHot: (120, 6)\n","   DocType OneHot: (120, 2)\n","\n","üîÑ CHU·∫®N H√ìA C√ÅC FEATURE MATRICES:\n","‚úÖ ƒê√£ chu·∫©n h√≥a t·∫•t c·∫£ feature matrices\n","\n","‚öñÔ∏è √ÅP D·ª§NG TR·ªåNG S·ªê M·ªöI:\n","‚úÖ ƒê√£ √°p d·ª•ng tr·ªçng s·ªë m·ªõi cho t·ª´ng feature\n","   üìñ Title weight: 0.25\n","   üìÑ Description weight: 0.3 (gi·∫£m)\n","   üè∑Ô∏è Category weight: 0.35 (tƒÉng)\n","   üìã DocType weight: 0.1\n","\n","üîó K·∫æT H·ª¢P T·∫§T C·∫¢ FEATURES:\n","‚úÖ Combined features shape: (120, 2210)\n","üìä T·ªïng dimensions: 2210\n","\n","üîç KI·ªÇM TRA T√ÅC ƒê·ªòNG TR·ªåNG S·ªê M·ªöI:\n","\n","üìñ S√°ch 1: S√°ng t·∫°o b·ª´ng ch√°y s·ª©c m·∫°nh b√™n trong\n","   üè∑Ô∏è Category: Tri·∫øt h·ªçc\n","   üìñ Title component: 0.2500\n","   üìÑ Description component: 0.3000 (gi·∫£m weight)\n","   üè∑Ô∏è Category component: 0.3500 (tƒÉng weight)\n","   üìã DocType component: 0.1000\n","   üéØ Total vector norm: 0.5339\n","\n","üìñ S√°ch 2: Phong c√°ch h·ªçc ti·∫øng Vi·ªát\n","   üè∑Ô∏è Category: Gi√°o d·ª•c\n","   üìñ Title component: 0.2500\n","   üìÑ Description component: 0.3000 (gi·∫£m weight)\n","   üè∑Ô∏è Category component: 0.3500 (tƒÉng weight)\n","   üìã DocType component: 0.1000\n","   üéØ Total vector norm: 0.5339\n","\n","üìñ S√°ch 3: Tr√≠ tu·ªá Do Th√°i\n","   üè∑Ô∏è Category: Kinh t·∫ø\n","   üìñ Title component: 0.2500\n","   üìÑ Description component: 0.3000 (gi·∫£m weight)\n","   üè∑Ô∏è Category component: 0.3500 (tƒÉng weight)\n","   üìã DocType component: 0.1000\n","   üéØ Total vector norm: 0.5339\n","\n","üíæ ƒê√É HO√ÄN TH√ÄNH K·∫æT H·ª¢P FEATURES V·ªöI TR·ªåNG S·ªê M·ªöI!\n","üéØ Category importance tƒÉng l√™n ‚Üí recommendation theo ch·ªß ƒë·ªÅ t·ªët h∆°n!\n","üìè Final feature matrix: (120, 2210)\n"]}]},{"cell_type":"code","source":["# Cell 8: T√≠nh to√°n Cosine Similarity Matrix (FIXED)\n","from sklearn.metrics.pairwise import cosine_similarity\n","import numpy as np\n","import time\n","\n","print(\"üìê T√çNH TO√ÅN COSINE SIMILARITY MATRIX (FIXED)\")\n","print(\"=\"*50)\n","\n","# S·ª≠ d·ª•ng similarity_matrix ƒë√£ t√≠nh t·ª´ cell tr∆∞·ªõc\n","print(f\"üìä SIMILARITY MATRIX INFO:\")\n","print(f\"   üìè Shape: {similarity_matrix.shape}\")\n","print(f\"   üíæ Size: {similarity_matrix.nbytes / (1024*1024):.2f} MB\")\n","\n","# Ph√¢n t√≠ch similarity matrix (fixed)\n","print(f\"\\nüìä PH√ÇN T√çCH SIMILARITY MATRIX:\")\n","print(f\"   üìà Max similarity: {similarity_matrix.max():.4f}\")\n","print(f\"   üìâ Min similarity: {similarity_matrix.min():.4f}\")\n","print(f\"   üìä Mean similarity: {similarity_matrix.mean():.4f}\")\n","\n","# Fix: T√¨m top similar pairs ƒê√öNG C√ÅCH\n","print(f\"\\nüèÜ TOP 10 C·∫∂P S√ÅCH T∆Ø∆†NG T·ª∞ NH·∫§T (FIXED):\")\n","\n","# T·∫°o mask ƒë·ªÉ lo·∫°i b·ªè diagonal v√† lower triangle\n","mask = np.triu(np.ones_like(similarity_matrix, dtype=bool), k=1)\n","\n","# L·∫•y t·∫•t c·∫£ similarity scores v√† indices\n","similarities = similarity_matrix[mask]\n","indices = np.where(mask)\n","\n","# Sort ƒë·ªÉ l·∫•y top similarities\n","sorted_indices = np.argsort(similarities)[::-1]  # Descending order\n","\n","# Hi·ªÉn th·ªã top 10 pairs\n","for i in range(10):\n","    idx = sorted_indices[i]\n","    row_idx = indices[0][idx]\n","    col_idx = indices[1][idx]\n","    score = similarities[idx]\n","\n","    book1 = books_df.iloc[row_idx]['book_title']\n","    book2 = books_df.iloc[col_idx]['book_title']\n","    cat1 = books_df.iloc[row_idx]['book_category']\n","    cat2 = books_df.iloc[col_idx]['book_category']\n","    doc1 = books_df.iloc[row_idx]['book_document_type']\n","    doc2 = books_df.iloc[col_idx]['book_document_type']\n","\n","    print(f\"\\nüîó C·∫∑p {i+1} (Score: {score:.4f}):\")\n","    print(f\"   üìñ S√°ch 1: {book1}\")\n","    print(f\"      üè∑Ô∏è Category: {cat1} | üìÑ Type: {doc1}\")\n","    print(f\"   üìñ S√°ch 2: {book2}\")\n","    print(f\"      üè∑Ô∏è Category: {cat2} | üìÑ Type: {doc2}\")\n","\n","    # Ki·ªÉm tra xem c√≥ c√πng category kh√¥ng\n","    same_category = \"‚úÖ C√πng category\" if cat1 == cat2 else \"‚ùå Kh√°c category\"\n","    print(f\"   üéØ {same_category}\")\n","\n","# Ph√¢n t√≠ch similarity theo category\n","print(f\"\\nüè∑Ô∏è PH√ÇN T√çCH SIMILARITY THEO CATEGORY:\")\n","categories = books_df['book_category'].unique()\n","\n","category_stats = {}\n","for cat in categories:\n","    cat_indices = books_df[books_df['book_category'] == cat].index.tolist()\n","\n","    if len(cat_indices) > 1:\n","        # T√≠nh similarity trong c√πng category\n","        cat_similarities = []\n","        for i in range(len(cat_indices)):\n","            for j in range(i+1, len(cat_indices)):\n","                sim = similarity_matrix[cat_indices[i], cat_indices[j]]\n","                cat_similarities.append(sim)\n","\n","        if cat_similarities:\n","            mean_sim = np.mean(cat_similarities)\n","            max_sim = np.max(cat_similarities)\n","            min_sim = np.min(cat_similarities)\n","            count = len(cat_indices)\n","\n","            category_stats[cat] = {\n","                'mean': mean_sim,\n","                'max': max_sim,\n","                'min': min_sim,\n","                'count': count,\n","                'pairs': len(cat_similarities)\n","            }\n","\n","            print(f\"\\nüè∑Ô∏è {cat} ({count} s√°ch, {len(cat_similarities)} c·∫∑p):\")\n","            print(f\"   üìä Mean similarity: {mean_sim:.4f}\")\n","            print(f\"   üìà Max similarity: {max_sim:.4f}\")\n","            print(f\"   üìâ Min similarity: {min_sim:.4f}\")\n","\n","# Th·ªëng k√™ t·ªïng quan\n","print(f\"\\nüìà TH·ªêNG K√ä T·ªîNG QUAN:\")\n","all_similarities = similarities\n","print(f\"   üìä T·ªïng s·ªë c·∫∑p s√°ch: {len(all_similarities)}\")\n","print(f\"   üìà Similarity cao nh·∫•t: {all_similarities.max():.4f}\")\n","print(f\"   üìâ Similarity th·∫•p nh·∫•t: {all_similarities.min():.4f}\")\n","print(f\"   üìä Mean similarity: {all_similarities.mean():.4f}\")\n","print(f\"   üìè Std similarity: {all_similarities.std():.4f}\")\n","\n","# Ph√¢n b·ªë theo ng∆∞·ª°ng\n","high_sim = np.sum(all_similarities >= 0.7)\n","medium_sim = np.sum((all_similarities >= 0.4) & (all_similarities < 0.7))\n","low_sim = np.sum(all_similarities < 0.4)\n","\n","print(f\"\\nüìä PH√ÇN B·ªê SIMILARITY:\")\n","print(f\"   üî• High (‚â•0.7): {high_sim} c·∫∑p ({high_sim/len(all_similarities)*100:.1f}%)\")\n","print(f\"   üî∂ Medium (0.4-0.7): {medium_sim} c·∫∑p ({medium_sim/len(all_similarities)*100:.1f}%)\")\n","print(f\"   üîµ Low (<0.4): {low_sim} c·∫∑p ({low_sim/len(all_similarities)*100:.1f}%)\")\n","\n","print(f\"\\n‚úÖ ƒê√É FIX XONG! TOP PAIRS HI·ªÇN TH·ªä CH√çNH X√ÅC!\")\n","print(f\"üéØ S·∫¥N S√ÄNG X√ÇY D·ª∞NG RECOMMENDATION FUNCTION!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"15oq6QamQ80w","executionInfo":{"status":"ok","timestamp":1754281020515,"user_tz":-420,"elapsed":84,"user":{"displayName":"Le Nguyen Thai Tuan B2113346","userId":"03563100155966040964"}},"outputId":"c0c45dac-71ff-4627-be50-6311667c7054"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["üìê T√çNH TO√ÅN COSINE SIMILARITY MATRIX (FIXED)\n","==================================================\n","üìä SIMILARITY MATRIX INFO:\n","   üìè Shape: (120, 120)\n","   üíæ Size: 0.11 MB\n","\n","üìä PH√ÇN T√çCH SIMILARITY MATRIX:\n","   üìà Max similarity: 1.0000\n","   üìâ Min similarity: 0.0035\n","   üìä Mean similarity: 0.1582\n","\n","üèÜ TOP 10 C·∫∂P S√ÅCH T∆Ø∆†NG T·ª∞ NH·∫§T (FIXED):\n","\n","üîó C·∫∑p 1 (Score: 0.8596):\n","   üìñ S√°ch 1: L·∫≠p tr√¨nh h∆∞·ªõng ƒë·ªëi t∆∞·ª£ng\n","      üè∑Ô∏è Category: C√¥ng ngh·ªá th√¥ng tin | üìÑ Type: textbook\n","   üìñ S√°ch 2: L·∫≠p tr√¨nh h∆∞·ªõng ƒë·ªëi t∆∞·ª£ng Java\n","      üè∑Ô∏è Category: C√¥ng ngh·ªá th√¥ng tin | üìÑ Type: textbook\n","   üéØ ‚úÖ C√πng category\n","\n","üîó C·∫∑p 2 (Score: 0.8057):\n","   üìñ S√°ch 1: L·∫≠p tr√¨nh h∆∞·ªõng ƒë·ªëi t∆∞·ª£ng Java\n","      üè∑Ô∏è Category: C√¥ng ngh·ªá th√¥ng tin | üìÑ Type: textbook\n","   üìñ S√°ch 2: L·∫≠p tr√¨nh .Net\n","      üè∑Ô∏è Category: C√¥ng ngh·ªá th√¥ng tin | üìÑ Type: textbook\n","   üéØ ‚úÖ C√πng category\n","\n","üîó C·∫∑p 3 (Score: 0.8003):\n","   üìñ S√°ch 1: L·∫≠p tr√¨nh .Net\n","      üè∑Ô∏è Category: C√¥ng ngh·ªá th√¥ng tin | üìÑ Type: textbook\n","   üìñ S√°ch 2: L·∫≠p tr√¨nh Web\n","      üè∑Ô∏è Category: C√¥ng ngh·ªá th√¥ng tin | üìÑ Type: textbook\n","   üéØ ‚úÖ C√πng category\n","\n","üîó C·∫∑p 4 (Score: 0.7999):\n","   üìñ S√°ch 1: S·ª± im l·∫∑ng c·ªßa b·∫ßy c·ª´u\n","      üè∑Ô∏è Category: VƒÉn h·ªçc | üìÑ Type: other\n","   üìñ S√°ch 2: Lu·∫≠t im l·∫∑ng\n","      üè∑Ô∏è Category: VƒÉn h·ªçc | üìÑ Type: other\n","   üéØ ‚úÖ C√πng category\n","\n","üîó C·∫∑p 5 (Score: 0.7861):\n","   üìñ S√°ch 1: S·ªï tay H∆∞·ªõng d·∫´n s·∫£n xu·∫•t ƒë·∫•t nung l√†m v·∫≠t li·ªáu h·∫•p ph·ª• l√¢n trong n∆∞·ªõc th·∫£i\n","      üè∑Ô∏è Category: Khoa h·ªçc t·ª± nhi√™n | üìÑ Type: other\n","   üìñ S√°ch 2: S·ªï tay H∆∞·ªõng d·∫´n s·∫£n xu·∫•t than\n","      üè∑Ô∏è Category: Khoa h·ªçc t·ª± nhi√™n | üìÑ Type: other\n","   üéØ ‚úÖ C√πng category\n","\n","üîó C·∫∑p 6 (Score: 0.7783):\n","   üìñ S√°ch 1: Dinh d∆∞·ª°ng ƒë·ªông v·∫≠t th·ªßy s·∫£n - ·∫¢nh h∆∞·ªüng c·ªßa nhi·ªát ƒë·ªô v√† ƒë·ªô m·∫∑n\n","      üè∑Ô∏è Category: Khoa h·ªçc t·ª± nhi√™n | üìÑ Type: other\n","   üìñ S√°ch 2: S·ª± bi·∫øn ƒë·ªïi ch·∫•t l∆∞·ª£ng c·ªßa ƒë·ªông v·∫≠t th·ªßy s·∫£n\n","      üè∑Ô∏è Category: Khoa h·ªçc t·ª± nhi√™n | üìÑ Type: other\n","   üéØ ‚úÖ C√πng category\n","\n","üîó C·∫∑p 7 (Score: 0.7753):\n","   üìñ S√°ch 1: L·∫≠p tr√¨nh song song\n","      üè∑Ô∏è Category: C√¥ng ngh·ªá th√¥ng tin | üìÑ Type: textbook\n","   üìñ S√°ch 2: L·∫≠p tr√¨nh Web\n","      üè∑Ô∏è Category: C√¥ng ngh·ªá th√¥ng tin | üìÑ Type: textbook\n","   üéØ ‚úÖ C√πng category\n","\n","üîó C·∫∑p 8 (Score: 0.7731):\n","   üìñ S√°ch 1: S·ªï tay K·ªπ thu·∫≠t chuy·ªÉn gen th√¥ng qua vi khu·∫©n Agrobacterium Tumefaciens tr√™n gi·ªëng l√∫a indica\n","      üè∑Ô∏è Category: Khoa h·ªçc t·ª± nhi√™n | üìÑ Type: other\n","   üìñ S√°ch 2: Ch·ªâ th·ªã gen ch·ª©c nƒÉng trong ch·ªçn gi·ªëng l√∫a\n","      üè∑Ô∏è Category: Khoa h·ªçc t·ª± nhi√™n | üìÑ Type: other\n","   üéØ ‚úÖ C√πng category\n","\n","üîó C·∫∑p 9 (Score: 0.7633):\n","   üìñ S√°ch 1: B√≥ng r·ªï\n","      üè∑Ô∏è Category: Gi√°o d·ª•c | üìÑ Type: textbook\n","   üìñ S√°ch 2: Taekwondo\n","      üè∑Ô∏è Category: Gi√°o d·ª•c | üìÑ Type: textbook\n","   üéØ ‚úÖ C√πng category\n","\n","üîó C·∫∑p 10 (Score: 0.7541):\n","   üìñ S√°ch 1: H·ªá qu·∫£n tr·ªã c∆° s·ªü d·ªØ li·ªáu\n","      üè∑Ô∏è Category: C√¥ng ngh·ªá th√¥ng tin | üìÑ Type: textbook\n","   üìñ S√°ch 2: H·ªá c∆° s·ªü d·ªØ li·ªáu ƒëa ph∆∞∆°ng ti·ªán\n","      üè∑Ô∏è Category: C√¥ng ngh·ªá th√¥ng tin | üìÑ Type: textbook\n","   üéØ ‚úÖ C√πng category\n","\n","üè∑Ô∏è PH√ÇN T√çCH SIMILARITY THEO CATEGORY:\n","\n","üè∑Ô∏è Tri·∫øt h·ªçc (13 s√°ch, 78 c·∫∑p):\n","   üìä Mean similarity: 0.5434\n","   üìà Max similarity: 0.6647\n","   üìâ Min similarity: 0.4800\n","\n","üè∑Ô∏è Gi√°o d·ª•c (9 s√°ch, 36 c·∫∑p):\n","   üìä Mean similarity: 0.5346\n","   üìà Max similarity: 0.7633\n","   üìâ Min similarity: 0.4541\n","\n","üè∑Ô∏è Kinh t·∫ø (13 s√°ch, 78 c·∫∑p):\n","   üìä Mean similarity: 0.5706\n","   üìà Max similarity: 0.7319\n","   üìâ Min similarity: 0.5195\n","\n","üè∑Ô∏è C√¥ng ngh·ªá th√¥ng tin (28 s√°ch, 378 c·∫∑p):\n","   üìä Mean similarity: 0.5474\n","   üìà Max similarity: 0.8596\n","   üìâ Min similarity: 0.4601\n","\n","üè∑Ô∏è VƒÉn h·ªçc (19 s√°ch, 171 c·∫∑p):\n","   üìä Mean similarity: 0.5728\n","   üìà Max similarity: 0.7999\n","   üìâ Min similarity: 0.5104\n","\n","üè∑Ô∏è Khoa h·ªçc t·ª± nhi√™n (38 s√°ch, 703 c·∫∑p):\n","   üìä Mean similarity: 0.5150\n","   üìà Max similarity: 0.7861\n","   üìâ Min similarity: 0.4352\n","\n","üìà TH·ªêNG K√ä T·ªîNG QUAN:\n","   üìä T·ªïng s·ªë c·∫∑p s√°ch: 7140\n","   üìà Similarity cao nh·∫•t: 0.8596\n","   üìâ Similarity th·∫•p nh·∫•t: 0.0035\n","   üìä Mean similarity: 0.1512\n","   üìè Std similarity: 0.1976\n","\n","üìä PH√ÇN B·ªê SIMILARITY:\n","   üî• High (‚â•0.7): 23 c·∫∑p (0.3%)\n","   üî∂ Medium (0.4-0.7): 1421 c·∫∑p (19.9%)\n","   üîµ Low (<0.4): 5696 c·∫∑p (79.8%)\n","\n","‚úÖ ƒê√É FIX XONG! TOP PAIRS HI·ªÇN TH·ªä CH√çNH X√ÅC!\n","üéØ S·∫¥N S√ÄNG X√ÇY D·ª∞NG RECOMMENDATION FUNCTION!\n"]}]},{"cell_type":"markdown","source":["üìã TR·∫†NG TH√ÅI ITEM PROFILE - ƒê√É HO√ÄN TH√ÄNH:\n","‚úÖ ITEM PROFILE ƒê√É X√ÇY D·ª∞NG XONG:\n","üìç V·ªä TR√ç ITEM PROFILES:\n","\n","Python\n","# Item profiles ƒë∆∞·ª£c l∆∞u trong:\n","combined_features  # Shape: (120, 2210) - ma tr·∫≠n feature cho 120 s√°ch\n","üéØ C·∫§U TR√öC ITEM PROFILE CHO M·ªñI S√ÅCH:\n","\n","Code\n","M·ªói s√°ch c√≥ vector 2210 dimensions:\n","‚îú‚îÄ‚îÄ Title TF-IDF: [0:202] - 202 dims (weight: 0.25)\n","‚îú‚îÄ‚îÄ Description TF-IDF: [202:2202] - 2000 dims (weight: 0.3)\n","‚îú‚îÄ‚îÄ Category OneHot: [2202:2208] - 6 dims (weight: 0.35)\n","‚îî‚îÄ‚îÄ DocType OneHot: [2208:2210] - 2 dims (weight: 0.1)\n","üìä CHI TI·∫æT ITEM PROFILES:\n","üìù Metadata ƒë∆∞·ª£c l∆∞u trong:\n","\n","Python\n","feature_info = {\n","    'matrix': combined_features,        # Ma tr·∫≠n features\n","    'dimensions': {...},                # Mapping dimensions\n","    'weights': {...},                   # Tr·ªçng s·ªë features\n","    'total_dims': 2210                 # T·ªïng dimensions\n","}\n","\n","books_df  # DataFrame ch·ª©a th√¥ng tin s√°ch (title, category, description...)\n","üéØ TR·∫†NG TH√ÅI HI·ªÜN T·∫†I:\n","‚úÖ ƒê√É HO√ÄN TH√ÄNH:\n","\n","‚úÖ Text preprocessing (title, description)\n","‚úÖ TF-IDF vectorization\n","‚úÖ Categorical encoding (category, doc_type)\n","‚úÖ Feature combination v·ªõi weights\n","‚úÖ Similarity matrix calculation\n","üöÄ S·∫¥N S√ÄNG CHO:\n","\n","Content-Based Recommendation Function\n","User query processing\n","Real-time recommendation\n","Item profiles ƒë√£ s·∫µn s√†ng ƒë·ªÉ build recommendation system! üéâ"],"metadata":{"id":"9iZMY3bqUiyn"}},{"cell_type":"code","source":["# Cell 9 Fixed: Item-Based Recommendation v·ªõi MongoDB ObjectId\n","import pandas as pd\n","import numpy as np\n","\n","print(\"üéØ X√ÇY D·ª∞NG ITEM-BASED RECOMMENDATION SYSTEM (MongoDB Compatible)\")\n","print(\"=\"*70)\n","\n","def create_book_id_mapping():\n","    \"\"\"\n","    T·∫°o mapping gi·ªØa MongoDB ObjectId v√† DataFrame index\n","    \"\"\"\n","    # Gi·∫£ s·ª≠ books_df c√≥ c·ªôt 'book_id' ch·ª©a MongoDB ObjectId\n","    if 'book_id' not in books_df.columns:\n","        # N·∫øu ch∆∞a c√≥, t·∫°o fake ObjectIds ƒë·ªÉ demo\n","        from bson import ObjectId\n","        books_df['book_id'] = [ObjectId() for _ in range(len(books_df))]\n","\n","    # T·∫°o mapping dict\n","    objectid_to_index = {str(books_df.iloc[i]['book_id']): i for i in range(len(books_df))}\n","    index_to_objectid = {i: str(books_df.iloc[i]['book_id']) for i in range(len(books_df))}\n","\n","    print(f\"‚úÖ T·∫°o mapping cho {len(books_df)} s√°ch\")\n","    print(f\"üìù Sample mapping:\")\n","    for i in range(min(3, len(books_df))):\n","        obj_id = index_to_objectid[i]\n","        print(f\"   Index {i} ‚Üî ObjectId {obj_id[:12]}...\")\n","\n","    return objectid_to_index, index_to_objectid\n","\n","def recommend_by_mongodb_id(mongodb_book_id, top_k=5, min_similarity=0.1):\n","    \"\"\"\n","    G·ª£i √Ω s√°ch t∆∞∆°ng t·ª± d·ª±a tr√™n MongoDB ObjectId\n","\n","    Parameters:\n","    - mongodb_book_id: ObjectId c·ªßa s√°ch t·ª´ MongoDB (string)\n","    - top_k: s·ªë l∆∞·ª£ng s√°ch g·ª£i √Ω\n","    - min_similarity: ng∆∞·ª°ng similarity t·ªëi thi·ªÉu\n","\n","    Returns:\n","    - List of recommended books v·ªõi MongoDB ObjectId\n","    \"\"\"\n","    print(f\"üîç T√¨m s√°ch t∆∞∆°ng t·ª± cho MongoDB ID: {mongodb_book_id}\")\n","\n","    # Convert MongoDB ObjectId to DataFrame index\n","    if mongodb_book_id not in objectid_to_index:\n","        print(f\"‚ùå Kh√¥ng t√¨m th·∫•y s√°ch v·ªõi ID: {mongodb_book_id}\")\n","        return []\n","\n","    df_index = objectid_to_index[mongodb_book_id]\n","    print(f\"üìç Mapped to DataFrame index: {df_index}\")\n","\n","    # S·ª≠ d·ª•ng function recommendation c≈© v·ªõi df_index\n","    source_book = books_df.iloc[df_index]\n","    print(f\"üìñ S√°ch g·ªëc: {source_book['book_title']}\")\n","    print(f\"üè∑Ô∏è Category: {source_book['book_category']}\")\n","\n","    # L·∫•y similarity scores\n","    book_similarities = similarity_matrix[df_index].copy()\n","    book_similarities[df_index] = -1  # Lo·∫°i b·ªè ch√≠nh n√≥\n","\n","    # L·ªçc v√† sort\n","    valid_indices = np.where(book_similarities >= min_similarity)[0]\n","    if len(valid_indices) == 0:\n","        print(f\"‚ùå Kh√¥ng t√¨m th·∫•y s√°ch t∆∞∆°ng t·ª±\")\n","        return []\n","\n","    sorted_indices = valid_indices[np.argsort(book_similarities[valid_indices])[::-1]]\n","    top_indices = sorted_indices[:top_k]\n","\n","    # T·∫°o k·∫øt qu·∫£ v·ªõi MongoDB ObjectIds\n","    recommendations = []\n","\n","    print(f\"\\nüèÜ TOP {len(top_indices)} S√ÅCH T∆Ø∆†NG T·ª∞:\")\n","    print(\"-\" * 80)\n","\n","    for i, idx in enumerate(top_indices):\n","        book = books_df.iloc[idx]\n","        mongodb_id = index_to_objectid[idx]\n","        similarity_score = book_similarities[idx]\n","\n","        rec = {\n","            'mongodb_book_id': mongodb_id,\n","            'book_title': book['book_title'],\n","            'book_category': book['book_category'],\n","            'book_document_type': book['book_document_type'],\n","            'similarity_score': float(similarity_score),\n","            'rank': i + 1\n","        }\n","\n","        recommendations.append(rec)\n","\n","        # Hi·ªÉn th·ªã\n","        same_category = \"‚úÖ\" if book['book_category'] == source_book['book_category'] else \"‚ùå\"\n","        print(f\"{i+1:2d}. üìö {book['book_title'][:50]}\")\n","        print(f\"    üÜî MongoDB ID: {mongodb_id}\")\n","        print(f\"    üè∑Ô∏è {book['book_category']} {same_category}\")\n","        print(f\"    üìä Similarity: {similarity_score:.4f}\")\n","        print()\n","\n","    return recommendations\n","\n","def get_book_info_by_mongodb_id(mongodb_book_id):\n","    \"\"\"\n","    L·∫•y th√¥ng tin s√°ch theo MongoDB ObjectId\n","    \"\"\"\n","    if mongodb_book_id not in objectid_to_index:\n","        return None\n","\n","    df_index = objectid_to_index[mongodb_book_id]\n","    book = books_df.iloc[df_index]\n","\n","    return {\n","        'mongodb_book_id': mongodb_book_id,\n","        'df_index': df_index,\n","        'book_title': book['book_title'],\n","        'book_category': book['book_category'],\n","        'book_document_type': book['book_document_type']\n","    }\n","\n","# T·∫°o mapping system\n","objectid_to_index, index_to_objectid = create_book_id_mapping()\n","\n","# Test v·ªõi MongoDB ObjectId\n","print(f\"\\nüß™ TESTING V·ªöI MONGODB OBJECTID:\")\n","print(\"=\" * 50)\n","\n","# L·∫•y m·ªôt MongoDB ID ƒë·ªÉ test\n","test_mongodb_id = index_to_objectid[0]  # S√°ch ƒë·∫ßu ti√™n\n","print(f\"\\nüéØ Test v·ªõi MongoDB ID: {test_mongodb_id}\")\n","\n","# Get book info\n","book_info = get_book_info_by_mongodb_id(test_mongodb_id)\n","if book_info:\n","    print(f\"üìñ S√°ch: {book_info['book_title']}\")\n","    print(f\"üè∑Ô∏è Category: {book_info['book_category']}\")\n","\n","# Get recommendations\n","recommendations = recommend_by_mongodb_id(test_mongodb_id, top_k=3)\n","\n","print(f\"\\nüîó K·∫æT QU·∫¢ CHO WEBSITE:\")\n","print(\"=\" * 30)\n","print(\"üì§ API Response format:\")\n","for rec in recommendations[:2]:  # Show first 2\n","    print(f\"   - MongoDB ID: {rec['mongodb_book_id']}\")\n","    print(f\"     Title: {rec['book_title']}\")\n","    print(f\"     Score: {rec['similarity_score']:.4f}\")\n","\n","print(f\"\\n‚úÖ S·∫¥N S√ÄNG INTEGRATE V·ªöI MONGODB!\")\n","print(f\"üåê Website c√≥ th·ªÉ g·ªçi: recommend_by_mongodb_id(bookId)\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8i9-h7zHVGm8","executionInfo":{"status":"ok","timestamp":1754282213722,"user_tz":-420,"elapsed":89,"user":{"displayName":"Le Nguyen Thai Tuan B2113346","userId":"03563100155966040964"}},"outputId":"34409911-cce8-4bf7-8007-5d3a4b90fdce"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["üéØ X√ÇY D·ª∞NG ITEM-BASED RECOMMENDATION SYSTEM (MongoDB Compatible)\n","======================================================================\n","‚úÖ T·∫°o mapping cho 120 s√°ch\n","üìù Sample mapping:\n","   Index 0 ‚Üî ObjectId 6887514a9e6f...\n","   Index 1 ‚Üî ObjectId 68859b92dbd8...\n","   Index 2 ‚Üî ObjectId 68886c8a4059...\n","\n","üß™ TESTING V·ªöI MONGODB OBJECTID:\n","==================================================\n","\n","üéØ Test v·ªõi MongoDB ID: 6887514a9e6faeb381cc3a43\n","üìñ S√°ch: S√°ng t·∫°o b·ª´ng ch√°y s·ª©c m·∫°nh b√™n trong\n","üè∑Ô∏è Category: Tri·∫øt h·ªçc\n","üîç T√¨m s√°ch t∆∞∆°ng t·ª± cho MongoDB ID: 6887514a9e6faeb381cc3a43\n","üìç Mapped to DataFrame index: 0\n","üìñ S√°ch g·ªëc: S√°ng t·∫°o b·ª´ng ch√°y s·ª©c m·∫°nh b√™n trong\n","üè∑Ô∏è Category: Tri·∫øt h·ªçc\n","\n","üèÜ TOP 3 S√ÅCH T∆Ø∆†NG T·ª∞:\n","--------------------------------------------------------------------------------\n"," 1. üìö Suy ng·∫´m v·ªÅ thi·ªán v√† √°c\n","    üÜî MongoDB ID: 68873f11e39419950ff0afe6\n","    üè∑Ô∏è Tri·∫øt h·ªçc ‚úÖ\n","    üìä Similarity: 0.5889\n","\n"," 2. üìö Tr∆∞·ªüng th√†nh\n","    üÜî MongoDB ID: 68874eb59e6faeb381cc399a\n","    üè∑Ô∏è Tri·∫øt h·ªçc ‚úÖ\n","    üìä Similarity: 0.5792\n","\n"," 3. üìö Lu·∫≠n v·ªÅ y√™u\n","    üÜî MongoDB ID: 6887542b9e6faeb381cc3ab6\n","    üè∑Ô∏è Tri·∫øt h·ªçc ‚úÖ\n","    üìä Similarity: 0.5731\n","\n","\n","üîó K·∫æT QU·∫¢ CHO WEBSITE:\n","==============================\n","üì§ API Response format:\n","   - MongoDB ID: 68873f11e39419950ff0afe6\n","     Title: Suy ng·∫´m v·ªÅ thi·ªán v√† √°c\n","     Score: 0.5889\n","   - MongoDB ID: 68874eb59e6faeb381cc399a\n","     Title: Tr∆∞·ªüng th√†nh\n","     Score: 0.5792\n","\n","‚úÖ S·∫¥N S√ÄNG INTEGRATE V·ªöI MONGODB!\n","üåê Website c√≥ th·ªÉ g·ªçi: recommend_by_mongodb_id(bookId)\n"]}]},{"cell_type":"code","source":["# Cell 10: Cold Start Recommendation System (Faculty-Based Mapping)\n","import pandas as pd\n","import numpy as np\n","\n","print(\"‚ùÑÔ∏è X√ÇY D·ª∞NG COLD START RECOMMENDATION SYSTEM (FACULTY MAPPING)\")\n","print(\"=\"*70)\n","\n","def get_faculty_recommendations(faculty_code, top_k=5):\n","    \"\"\"\n","    G·ª£i √Ω 100% s√°ch theo faculty code mapping\n","\n","    Parameters:\n","    - faculty_code: m√£ khoa (cntt, khtn, kinh_te, giao_duc, chinh_tri, van_hoc)\n","    - top_k: s·ªë s√°ch g·ª£i √Ω (default: 5)\n","\n","    Returns:\n","    - List of recommended books t·ª´ category t∆∞∆°ng ·ª©ng\n","    \"\"\"\n","\n","    # Faculty code mapping v·ªõi book categories\n","    faculty_to_category = {\n","        \"cntt\": \"C√¥ng ngh·ªá th√¥ng tin\",\n","        \"khtn\": \"Khoa h·ªçc t·ª± nhi√™n\",\n","        \"kinh_te\": \"Kinh t·∫ø\",\n","        \"giao_duc\": \"Gi√°o d·ª•c\",\n","        \"chinh_tri\": \"Tri·∫øt h·ªçc\",  # Map \"Ch√≠nh tr·ªã\" ‚Üí \"Tri·∫øt h·ªçc\" (available category)\n","        \"van_hoc\": \"VƒÉn h·ªçc\"\n","    }\n","\n","    faculty_code_lower = faculty_code.lower().strip()\n","    print(f\"üéì Processing faculty code: '{faculty_code}'\")\n","\n","    # Ki·ªÉm tra faculty code c√≥ trong mapping kh√¥ng\n","    if faculty_code_lower not in faculty_to_category:\n","        print(f\"‚ùå Faculty code '{faculty_code}' not found in mapping\")\n","        available_codes = list(faculty_to_category.keys())\n","        print(f\"üìã Available codes: {available_codes}\")\n","        return []\n","\n","    target_category = faculty_to_category[faculty_code_lower]\n","    print(f\"‚úÖ Mapped to category: '{target_category}'\")\n","\n","    # Ki·ªÉm tra category c√≥ t·ªìn t·∫°i trong data kh√¥ng\n","    available_categories = books_df['book_category'].unique().tolist()\n","    if target_category not in available_categories:\n","        print(f\"‚ùå Category '{target_category}' not found in books data\")\n","        print(f\"üìã Available categories: {available_categories}\")\n","        return []\n","\n","    # L·∫•y s√°ch t·ª´ category\n","    category_books = books_df[books_df['book_category'] == target_category]\n","\n","    if len(category_books) == 0:\n","        print(f\"‚ùå No books found in category: '{target_category}'\")\n","        return []\n","\n","    print(f\"üìö Found {len(category_books)} books in '{target_category}' category\")\n","\n","    # L·∫•y top K s√°ch (theo index - c√≥ th·ªÉ thay b·∫±ng rating/popularity)\n","    selected_books = category_books.head(top_k)\n","\n","    recommendations = []\n","    for i, (idx, row) in enumerate(selected_books.iterrows()):\n","        recommendations.append({\n","            'mongodb_book_id': index_to_objectid[idx],\n","            'book_title': row['book_title'],\n","            'book_category': row['book_category'],\n","            'book_document_type': row['book_document_type'],\n","            'faculty_match_score': 1.0 - (i * 0.1),\n","            'rank': i + 1,\n","            'faculty_code': faculty_code_lower,\n","            'matched_category': target_category\n","        })\n","\n","    print(f\"‚úÖ Generated {len(recommendations)} recommendations\")\n","    return recommendations\n","\n","def cold_start_recommendation(faculty_code=None, top_k=5):\n","    \"\"\"\n","    Main cold start recommendation function\n","\n","    Parameters:\n","    - faculty_code: m√£ khoa c·ªßa user (None n·∫øu kh√¥ng c√≥)\n","    - top_k: s·ªë s√°ch g·ª£i √Ω (default: 5)\n","\n","    Returns:\n","    - Dict with recommendations and cold_start_type for backend\n","    \"\"\"\n","    result = {\n","        'recommendations': [],\n","        'cold_start_type': None,\n","        'message': '',\n","        'total_count': 0,\n","        'faculty_code': faculty_code,\n","        'matched_category': None\n","    }\n","\n","    print(f\"‚ùÑÔ∏è COLD START RECOMMENDATION\")\n","    print(f\"üéì Faculty Code: {faculty_code}\")\n","    print(\"-\" * 50)\n","\n","    if faculty_code and faculty_code.strip():\n","        # Case: User c√≥ faculty code\n","        faculty_recs = get_faculty_recommendations(faculty_code, top_k)\n","\n","        if faculty_recs:\n","            result['recommendations'] = faculty_recs\n","            result['cold_start_type'] = 'FACULTY_BASED'\n","            result['message'] = f'Recommendations for faculty: {faculty_code}'\n","            result['total_count'] = len(faculty_recs)\n","            result['matched_category'] = faculty_recs[0]['matched_category']\n","            print(f\"‚úÖ SUCCESS: {len(faculty_recs)} faculty-based recommendations\")\n","        else:\n","            # Faculty code kh√¥ng map ƒë∆∞·ª£c ho·∫∑c kh√¥ng c√≥ s√°ch\n","            result['cold_start_type'] = 'SHOW_TRENDING'\n","            result['message'] = f'No books available for faculty: {faculty_code}'\n","            print(f\"‚ùå FALLBACK: No books for faculty '{faculty_code}' ‚Üí Show trending\")\n","    else:\n","        # Case: User kh√¥ng c√≥ faculty code (guest/not logged in)\n","        result['cold_start_type'] = 'SHOW_TRENDING'\n","        result['message'] = 'No faculty information available'\n","        print(f\"‚ùå FALLBACK: No faculty code ‚Üí Show trending\")\n","\n","    return result\n","\n","def display_cold_start_results(result):\n","    \"\"\"\n","    Hi·ªÉn th·ªã k·∫øt qu·∫£ cold start recommendations\n","    \"\"\"\n","    print(f\"\\nüìä COLD START RESULT:\")\n","    print(f\"   üè∑Ô∏è Type: {result['cold_start_type']}\")\n","    print(f\"   üéì Faculty: {result['faculty_code']}\")\n","    print(f\"   üìÇ Category: {result['matched_category']}\")\n","    print(f\"   üí¨ Message: {result['message']}\")\n","    print(f\"   üìö Count: {result['total_count']}\")\n","\n","    if result['recommendations']:\n","        print(f\"\\nüèÜ RECOMMENDATIONS:\")\n","        print(\"-\" * 70)\n","\n","        for book in result['recommendations']:\n","            print(f\"{book['rank']:2d}. üìö {book['book_title']}\")\n","            print(f\"    üÜî {book['mongodb_book_id'][:12]}...\")\n","            print(f\"    üè∑Ô∏è {book['book_category']} | üìÑ {book['book_document_type']}\")\n","            print(f\"    üìä Score: {book['faculty_match_score']:.3f}\")\n","            print()\n","    else:\n","        print(f\"\\nüîÑ Backend should show trending/popular books\")\n","\n","# Test t·∫•t c·∫£ faculty codes\n","print(f\"\\nüß™ TESTING ALL FACULTY CODES:\")\n","print(\"=\" * 60)\n","\n","faculty_codes = [\"cntt\", \"khtn\", \"kinh_te\", \"giao_duc\", \"chinh_tri\", \"van_hoc\"]\n","\n","for faculty_code in faculty_codes:\n","    print(f\"\\n‚ùÑÔ∏è Test Faculty: {faculty_code.upper()}\")\n","    result = cold_start_recommendation(faculty_code=faculty_code, top_k=5)\n","    display_cold_start_results(result)\n","    print(\"-\" * 50)\n","\n","# Test edge cases\n","print(f\"\\nüß™ TESTING EDGE CASES:\")\n","print(\"=\" * 40)\n","\n","# Test 1: Invalid faculty code\n","print(f\"\\n‚ùÑÔ∏è Test: Invalid Faculty Code\")\n","invalid_result = cold_start_recommendation(faculty_code=\"invalid_code\", top_k=5)\n","display_cold_start_results(invalid_result)\n","\n","# Test 2: No faculty code (Guest user)\n","print(f\"\\n‚ùÑÔ∏è Test: No Faculty Code (Guest)\")\n","guest_result = cold_start_recommendation(faculty_code=None, top_k=5)\n","display_cold_start_results(guest_result)\n","\n","# Test 3: Empty faculty code\n","print(f\"\\n‚ùÑÔ∏è Test: Empty Faculty Code\")\n","empty_result = cold_start_recommendation(faculty_code=\"\", top_k=5)\n","display_cold_start_results(empty_result)\n","\n","print(f\"\\n‚úÖ COLD START SYSTEM S·∫¥N S√ÄNG!\")\n","print(f\"\\nüåê BACKEND INTEGRATION:\")\n","print(f\"   üìã Cold Start Types:\")\n","print(f\"      - 'FACULTY_BASED': C√≥ recommendations ‚Üí Hi·ªÉn th·ªã recommendations\")\n","print(f\"      - 'SHOW_TRENDING': Kh√¥ng c√≥ recommendations ‚Üí Hi·ªÉn th·ªã trending books\")\n","print(f\"\\nüíª API Usage:\")\n","print(f\"   // User ƒë√£ ƒëƒÉng nh·∫≠p v·ªõi faculty\")\n","print(f\"   cold_start_recommendation(faculty_code='cntt', top_k=5)\")\n","print(f\"   \")\n","print(f\"   // Guest user ho·∫∑c no faculty\")\n","print(f\"   cold_start_recommendation(faculty_code=None, top_k=5)\")\n","print(f\"\\nüì¶ Response Format:\")\n","print(f\"   {{\")\n","print(f\"     'recommendations': [...],  // Array of books or []\")\n","print(f\"     'cold_start_type': 'FACULTY_BASED' | 'SHOW_TRENDING',\")\n","print(f\"     'message': 'Description',\")\n","print(f\"     'total_count': 5,\")\n","print(f\"     'faculty_code': 'cntt',\")\n","print(f\"     'matched_category': 'C√¥ng ngh·ªá th√¥ng tin'\")\n","print(f\"   }}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"29MRTBiXYNdu","executionInfo":{"status":"ok","timestamp":1754282870998,"user_tz":-420,"elapsed":119,"user":{"displayName":"Le Nguyen Thai Tuan B2113346","userId":"03563100155966040964"}},"outputId":"adc8d99a-7011-447e-a32d-adcb7b8a7b60"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["‚ùÑÔ∏è X√ÇY D·ª∞NG COLD START RECOMMENDATION SYSTEM (FACULTY MAPPING)\n","======================================================================\n","\n","üß™ TESTING ALL FACULTY CODES:\n","============================================================\n","\n","‚ùÑÔ∏è Test Faculty: CNTT\n","‚ùÑÔ∏è COLD START RECOMMENDATION\n","üéì Faculty Code: cntt\n","--------------------------------------------------\n","üéì Processing faculty code: 'cntt'\n","‚úÖ Mapped to category: 'C√¥ng ngh·ªá th√¥ng tin'\n","üìö Found 28 books in 'C√¥ng ngh·ªá th√¥ng tin' category\n","‚úÖ Generated 5 recommendations\n","‚úÖ SUCCESS: 5 faculty-based recommendations\n","\n","üìä COLD START RESULT:\n","   üè∑Ô∏è Type: FACULTY_BASED\n","   üéì Faculty: cntt\n","   üìÇ Category: C√¥ng ngh·ªá th√¥ng tin\n","   üí¨ Message: Recommendations for faculty: cntt\n","   üìö Count: 5\n","\n","üèÜ RECOMMENDATIONS:\n","----------------------------------------------------------------------\n"," 1. üìö Khai th√°c d·ªØ li·ªáu v·ªõi Python\n","    üÜî 6884b3db381c...\n","    üè∑Ô∏è C√¥ng ngh·ªá th√¥ng tin | üìÑ textbook\n","    üìä Score: 1.000\n","\n"," 2. üìö C√¥ng ngh·ªá J2EE\n","    üÜî 6884bbd46ac4...\n","    üè∑Ô∏è C√¥ng ngh·ªá th√¥ng tin | üìÑ textbook\n","    üìä Score: 0.900\n","\n"," 3. üìö M·∫°ng m√°y t√≠nh\n","    üÜî 6884b6f5381c...\n","    üè∑Ô∏è C√¥ng ngh·ªá th√¥ng tin | üìÑ textbook\n","    üìä Score: 0.800\n","\n"," 4. üìö H·ªá th·ªëng m√°y v√† thi·∫øt b·ªã l·∫°nh\n","    üÜî 6884bed96ac4...\n","    üè∑Ô∏è C√¥ng ngh·ªá th√¥ng tin | üìÑ textbook\n","    üìä Score: 0.700\n","\n"," 5. üìö L·∫≠p tr√¨nh song song\n","    üÜî 6884a887381c...\n","    üè∑Ô∏è C√¥ng ngh·ªá th√¥ng tin | üìÑ textbook\n","    üìä Score: 0.600\n","\n","--------------------------------------------------\n","\n","‚ùÑÔ∏è Test Faculty: KHTN\n","‚ùÑÔ∏è COLD START RECOMMENDATION\n","üéì Faculty Code: khtn\n","--------------------------------------------------\n","üéì Processing faculty code: 'khtn'\n","‚úÖ Mapped to category: 'Khoa h·ªçc t·ª± nhi√™n'\n","üìö Found 38 books in 'Khoa h·ªçc t·ª± nhi√™n' category\n","‚úÖ Generated 5 recommendations\n","‚úÖ SUCCESS: 5 faculty-based recommendations\n","\n","üìä COLD START RESULT:\n","   üè∑Ô∏è Type: FACULTY_BASED\n","   üéì Faculty: khtn\n","   üìÇ Category: Khoa h·ªçc t·ª± nhi√™n\n","   üí¨ Message: Recommendations for faculty: khtn\n","   üìö Count: 5\n","\n","üèÜ RECOMMENDATIONS:\n","----------------------------------------------------------------------\n"," 1. üìö An to√†n, s·ª©c kh·ªèe v√† m√¥i tr∆∞·ªùng\n","    üÜî 6885b241dbd8...\n","    üè∑Ô∏è Khoa h·ªçc t·ª± nhi√™n | üìÑ textbook\n","    üìä Score: 1.000\n","\n"," 2. üìö S·ªï tay K·ªπ thu·∫≠t chuy·ªÉn gen th√¥ng qua vi khu·∫©n Agrobacterium Tumefaciens tr√™n gi·ªëng l√∫a indica\n","    üÜî 6885a82bdbd8...\n","    üè∑Ô∏è Khoa h·ªçc t·ª± nhi√™n | üìÑ other\n","    üìä Score: 0.900\n","\n"," 3. üìö B·∫£o qu·∫£n sau thu ho·∫°ch v√† ngh·ªá thu·∫≠t c·∫Øm hoa\n","    üÜî 68863f800304...\n","    üè∑Ô∏è Khoa h·ªçc t·ª± nhi√™n | üìÑ textbook\n","    üìä Score: 0.800\n","\n"," 4. üìö K·ªπ thu·∫≠t nu√¥i c√° tra (Pangasianodon hypophthalmus) th∆∞∆°ng ph·∫©m c·∫£i ti·∫øn v√† li√™n k·∫øt trong s·∫£n xu·∫•t\n","    üÜî 6885b71edbd8...\n","    üè∑Ô∏è Khoa h·ªçc t·ª± nhi√™n | üìÑ other\n","    üìä Score: 0.700\n","\n"," 5. üìö Nu√¥i c·∫•y m√¥ th·ª±c v·∫≠t Nguy√™n l√Ω v√† th·ª±c h√†nh\n","    üÜî 6885a47adbd8...\n","    üè∑Ô∏è Khoa h·ªçc t·ª± nhi√™n | üìÑ other\n","    üìä Score: 0.600\n","\n","--------------------------------------------------\n","\n","‚ùÑÔ∏è Test Faculty: KINH_TE\n","‚ùÑÔ∏è COLD START RECOMMENDATION\n","üéì Faculty Code: kinh_te\n","--------------------------------------------------\n","üéì Processing faculty code: 'kinh_te'\n","‚úÖ Mapped to category: 'Kinh t·∫ø'\n","üìö Found 13 books in 'Kinh t·∫ø' category\n","‚úÖ Generated 5 recommendations\n","‚úÖ SUCCESS: 5 faculty-based recommendations\n","\n","üìä COLD START RESULT:\n","   üè∑Ô∏è Type: FACULTY_BASED\n","   üéì Faculty: kinh_te\n","   üìÇ Category: Kinh t·∫ø\n","   üí¨ Message: Recommendations for faculty: kinh_te\n","   üìö Count: 5\n","\n","üèÜ RECOMMENDATIONS:\n","----------------------------------------------------------------------\n"," 1. üìö Tr√≠ tu·ªá Do Th√°i\n","    üÜî 68886c8a4059...\n","    üè∑Ô∏è Kinh t·∫ø | üìÑ other\n","    üìä Score: 1.000\n","\n"," 2. üìö N·ªÅn gi√°o d·ª•c c·ªßa ng∆∞·ªùi gi√†u\n","    üÜî 68886a694059...\n","    üè∑Ô∏è Kinh t·∫ø | üìÑ other\n","    üìä Score: 0.900\n","\n"," 3. üìö Tr√≠ tu·ªá t√†i ch√≠nh\n","    üÜî 6889084612d7...\n","    üè∑Ô∏è Kinh t·∫ø | üìÑ other\n","    üìä Score: 0.800\n","\n"," 4. üìö Nh·ªØng k·∫ª xu·∫•t ch√∫ng\n","    üÜî 6889092612d7...\n","    üè∑Ô∏è Kinh t·∫ø | üìÑ other\n","    üìä Score: 0.700\n","\n"," 5. üìö Si√™u nƒÉng su·∫•t\n","    üÜî 6889040a12d7...\n","    üè∑Ô∏è Kinh t·∫ø | üìÑ other\n","    üìä Score: 0.600\n","\n","--------------------------------------------------\n","\n","‚ùÑÔ∏è Test Faculty: GIAO_DUC\n","‚ùÑÔ∏è COLD START RECOMMENDATION\n","üéì Faculty Code: giao_duc\n","--------------------------------------------------\n","üéì Processing faculty code: 'giao_duc'\n","‚úÖ Mapped to category: 'Gi√°o d·ª•c'\n","üìö Found 9 books in 'Gi√°o d·ª•c' category\n","‚úÖ Generated 5 recommendations\n","‚úÖ SUCCESS: 5 faculty-based recommendations\n","\n","üìä COLD START RESULT:\n","   üè∑Ô∏è Type: FACULTY_BASED\n","   üéì Faculty: giao_duc\n","   üìÇ Category: Gi√°o d·ª•c\n","   üí¨ Message: Recommendations for faculty: giao_duc\n","   üìö Count: 5\n","\n","üèÜ RECOMMENDATIONS:\n","----------------------------------------------------------------------\n"," 1. üìö Phong c√°ch h·ªçc ti·∫øng Vi·ªát\n","    üÜî 68859b92dbd8...\n","    üè∑Ô∏è Gi√°o d·ª•c | üìÑ textbook\n","    üìä Score: 1.000\n","\n"," 2. üìö B√≥ng r·ªï\n","    üÜî 68859c5adbd8...\n","    üè∑Ô∏è Gi√°o d·ª•c | üìÑ textbook\n","    üìä Score: 0.900\n","\n"," 3. üìö Qu·∫£n tr·ªã chi·∫øn l∆∞·ª£c\n","    üÜî 68859d44dbd8...\n","    üè∑Ô∏è Gi√°o d·ª•c | üìÑ textbook\n","    üìä Score: 0.800\n","\n"," 4. üìö Th·ªÉ d·ª•c\n","    üÜî 68859ab1dbd8...\n","    üè∑Ô∏è Gi√°o d·ª•c | üìÑ textbook\n","    üìä Score: 0.700\n","\n"," 5. üìö Chuy√™n ƒë·ªÅ T∆∞ t∆∞·ªüng H·ªì Ch√≠ Minh\n","    üÜî 688636280304...\n","    üè∑Ô∏è Gi√°o d·ª•c | üìÑ textbook\n","    üìä Score: 0.600\n","\n","--------------------------------------------------\n","\n","‚ùÑÔ∏è Test Faculty: CHINH_TRI\n","‚ùÑÔ∏è COLD START RECOMMENDATION\n","üéì Faculty Code: chinh_tri\n","--------------------------------------------------\n","üéì Processing faculty code: 'chinh_tri'\n","‚úÖ Mapped to category: 'Tri·∫øt h·ªçc'\n","üìö Found 13 books in 'Tri·∫øt h·ªçc' category\n","‚úÖ Generated 5 recommendations\n","‚úÖ SUCCESS: 5 faculty-based recommendations\n","\n","üìä COLD START RESULT:\n","   üè∑Ô∏è Type: FACULTY_BASED\n","   üéì Faculty: chinh_tri\n","   üìÇ Category: Tri·∫øt h·ªçc\n","   üí¨ Message: Recommendations for faculty: chinh_tri\n","   üìö Count: 5\n","\n","üèÜ RECOMMENDATIONS:\n","----------------------------------------------------------------------\n"," 1. üìö S√°ng t·∫°o b·ª´ng ch√°y s·ª©c m·∫°nh b√™n trong\n","    üÜî 6887514a9e6f...\n","    üè∑Ô∏è Tri·∫øt h·ªçc | üìÑ other\n","    üìä Score: 1.000\n","\n"," 2. üìö Da th·ªãt trong cu·ªôc ch∆°i\n","    üÜî 688746a6e394...\n","    üè∑Ô∏è Tri·∫øt h·ªçc | üìÑ other\n","    üìä Score: 0.900\n","\n"," 3. üìö Khuy·∫øn h·ªçc\n","    üÜî 688752b89e6f...\n","    üè∑Ô∏è Tri·∫øt h·ªçc | üìÑ other\n","    üìä Score: 0.800\n","\n"," 4. üìö Lu·∫≠n v·ªÅ y√™u\n","    üÜî 6887542b9e6f...\n","    üè∑Ô∏è Tri·∫øt h·ªçc | üìÑ other\n","    üìä Score: 0.700\n","\n"," 5. üìö Tr∆∞·ªüng th√†nh\n","    üÜî 68874eb59e6f...\n","    üè∑Ô∏è Tri·∫øt h·ªçc | üìÑ other\n","    üìä Score: 0.600\n","\n","--------------------------------------------------\n","\n","‚ùÑÔ∏è Test Faculty: VAN_HOC\n","‚ùÑÔ∏è COLD START RECOMMENDATION\n","üéì Faculty Code: van_hoc\n","--------------------------------------------------\n","üéì Processing faculty code: 'van_hoc'\n","‚úÖ Mapped to category: 'VƒÉn h·ªçc'\n","üìö Found 19 books in 'VƒÉn h·ªçc' category\n","‚úÖ Generated 5 recommendations\n","‚úÖ SUCCESS: 5 faculty-based recommendations\n","\n","üìä COLD START RESULT:\n","   üè∑Ô∏è Type: FACULTY_BASED\n","   üéì Faculty: van_hoc\n","   üìÇ Category: VƒÉn h·ªçc\n","   üí¨ Message: Recommendations for faculty: van_hoc\n","   üìö Count: 5\n","\n","üèÜ RECOMMENDATIONS:\n","----------------------------------------------------------------------\n"," 1. üìö Ngh·ªÅ gi√∫p vi·ªác\n","    üÜî 68890aed12d7...\n","    üè∑Ô∏è VƒÉn h·ªçc | üìÑ other\n","    üìä Score: 1.000\n","\n"," 2. üìö B·∫£n nƒÉng\n","    üÜî 68890da912d7...\n","    üè∑Ô∏è VƒÉn h·ªçc | üìÑ other\n","    üìä Score: 0.900\n","\n"," 3. üìö NƒÉm ng∆∞·ªùi g·∫∑p tr√™n thi√™n ƒë∆∞·ªùng\n","    üÜî 68885cdc4059...\n","    üè∑Ô∏è VƒÉn h·ªçc | üìÑ other\n","    üìä Score: 0.800\n","\n"," 4. üìö T√¥i ƒëi h·ªçc\n","    üÜî 68890ce812d7...\n","    üè∑Ô∏è VƒÉn h·ªçc | üìÑ other\n","    üìä Score: 0.700\n","\n"," 5. üìö Truy·ªán Ki·ªÅu\n","    üÜî 6888630a4059...\n","    üè∑Ô∏è VƒÉn h·ªçc | üìÑ other\n","    üìä Score: 0.600\n","\n","--------------------------------------------------\n","\n","üß™ TESTING EDGE CASES:\n","========================================\n","\n","‚ùÑÔ∏è Test: Invalid Faculty Code\n","‚ùÑÔ∏è COLD START RECOMMENDATION\n","üéì Faculty Code: invalid_code\n","--------------------------------------------------\n","üéì Processing faculty code: 'invalid_code'\n","‚ùå Faculty code 'invalid_code' not found in mapping\n","üìã Available codes: ['cntt', 'khtn', 'kinh_te', 'giao_duc', 'chinh_tri', 'van_hoc']\n","‚ùå FALLBACK: No books for faculty 'invalid_code' ‚Üí Show trending\n","\n","üìä COLD START RESULT:\n","   üè∑Ô∏è Type: SHOW_TRENDING\n","   üéì Faculty: invalid_code\n","   üìÇ Category: None\n","   üí¨ Message: No books available for faculty: invalid_code\n","   üìö Count: 0\n","\n","üîÑ Backend should show trending/popular books\n","\n","‚ùÑÔ∏è Test: No Faculty Code (Guest)\n","‚ùÑÔ∏è COLD START RECOMMENDATION\n","üéì Faculty Code: None\n","--------------------------------------------------\n","‚ùå FALLBACK: No faculty code ‚Üí Show trending\n","\n","üìä COLD START RESULT:\n","   üè∑Ô∏è Type: SHOW_TRENDING\n","   üéì Faculty: None\n","   üìÇ Category: None\n","   üí¨ Message: No faculty information available\n","   üìö Count: 0\n","\n","üîÑ Backend should show trending/popular books\n","\n","‚ùÑÔ∏è Test: Empty Faculty Code\n","‚ùÑÔ∏è COLD START RECOMMENDATION\n","üéì Faculty Code: \n","--------------------------------------------------\n","‚ùå FALLBACK: No faculty code ‚Üí Show trending\n","\n","üìä COLD START RESULT:\n","   üè∑Ô∏è Type: SHOW_TRENDING\n","   üéì Faculty: \n","   üìÇ Category: None\n","   üí¨ Message: No faculty information available\n","   üìö Count: 0\n","\n","üîÑ Backend should show trending/popular books\n","\n","‚úÖ COLD START SYSTEM S·∫¥N S√ÄNG!\n","\n","üåê BACKEND INTEGRATION:\n","   üìã Cold Start Types:\n","      - 'FACULTY_BASED': C√≥ recommendations ‚Üí Hi·ªÉn th·ªã recommendations\n","      - 'SHOW_TRENDING': Kh√¥ng c√≥ recommendations ‚Üí Hi·ªÉn th·ªã trending books\n","\n","üíª API Usage:\n","   // User ƒë√£ ƒëƒÉng nh·∫≠p v·ªõi faculty\n","   cold_start_recommendation(faculty_code='cntt', top_k=5)\n","   \n","   // Guest user ho·∫∑c no faculty\n","   cold_start_recommendation(faculty_code=None, top_k=5)\n","\n","üì¶ Response Format:\n","   {\n","     'recommendations': [...],  // Array of books or []\n","     'cold_start_type': 'FACULTY_BASED' | 'SHOW_TRENDING',\n","     'message': 'Description',\n","     'total_count': 5,\n","     'faculty_code': 'cntt',\n","     'matched_category': 'C√¥ng ngh·ªá th√¥ng tin'\n","   }\n"]}]},{"cell_type":"code","source":["# Cell 11: Model Evaluation Framework\n","import pandas as pd\n","import numpy as np\n","from sklearn.metrics.pairwise import cosine_similarity\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","print(\"üìä X√ÇY D·ª∞NG FRAMEWORK ƒê√ÅNH GI√Å RECOMMENDATION SYSTEM\")\n","print(\"=\"*60)\n","\n","def evaluate_content_diversity():\n","    \"\"\"\n","    ƒê√°nh gi√° ƒë·ªô ƒëa d·∫°ng c·ªßa recommendations\n","    \"\"\"\n","    print(\"üé® ƒê√ÅNH GI√Å DIVERSITY:\")\n","\n","    # Test v·ªõi 10 s√°ch ng·∫´u nhi√™n\n","    sample_books = np.random.choice(len(books_df), 10, replace=False)\n","\n","    diversity_scores = []\n","    category_coverage = []\n","\n","    for book_id in sample_books:\n","        # Get recommendations\n","        similarities = similarity_matrix[book_id].copy()\n","        similarities[book_id] = -1\n","        top_5_indices = np.argsort(similarities)[-5:]\n","\n","        # T√≠nh diversity trong top 5\n","        top_5_books = books_df.iloc[top_5_indices]\n","        unique_categories = top_5_books['book_category'].nunique()\n","        unique_types = top_5_books['book_document_type'].nunique()\n","\n","        diversity_score = (unique_categories + unique_types) / 2\n","        diversity_scores.append(diversity_score)\n","        category_coverage.append(unique_categories)\n","\n","    avg_diversity = np.mean(diversity_scores)\n","    avg_category_coverage = np.mean(category_coverage)\n","\n","    print(f\"   üìä Average Diversity Score: {avg_diversity:.3f}\")\n","    print(f\"   üè∑Ô∏è Average Category Coverage: {avg_category_coverage:.3f}\")\n","    print(f\"   üìà Diversity Range: {min(diversity_scores):.3f} - {max(diversity_scores):.3f}\")\n","\n","    return {\n","        'avg_diversity': avg_diversity,\n","        'avg_category_coverage': avg_category_coverage,\n","        'diversity_scores': diversity_scores\n","    }\n","\n","def evaluate_category_precision():\n","    \"\"\"\n","    ƒê√°nh gi√° precision trong c√πng category\n","    \"\"\"\n","    print(\"\\nüéØ ƒê√ÅNH GI√Å CATEGORY PRECISION:\")\n","\n","    category_precisions = {}\n","\n","    for category in books_df['book_category'].unique():\n","        category_books = books_df[books_df['book_category'] == category].index.tolist()\n","\n","        if len(category_books) < 2:\n","            continue\n","\n","        precisions = []\n","\n","        for book_id in category_books[:5]:  # Test 5 s√°ch ƒë·∫ßu m·ªói category\n","            similarities = similarity_matrix[book_id].copy()\n","            similarities[book_id] = -1\n","            top_5_indices = np.argsort(similarities)[-5:]\n","\n","            # ƒê·∫øm s·ªë s√°ch c√πng category trong top 5\n","            same_category_count = sum(1 for idx in top_5_indices\n","                                    if books_df.iloc[idx]['book_category'] == category)\n","\n","            precision = same_category_count / 5\n","            precisions.append(precision)\n","\n","        category_precisions[category] = np.mean(precisions)\n","        print(f\"   üìö {category}: {np.mean(precisions):.3f}\")\n","\n","    overall_precision = np.mean(list(category_precisions.values()))\n","    print(f\"   üèÜ Overall Category Precision: {overall_precision:.3f}\")\n","\n","    return category_precisions\n","\n","def evaluate_similarity_distribution():\n","    \"\"\"\n","    Ph√¢n t√≠ch ph√¢n ph·ªëi similarity scores\n","    \"\"\"\n","    print(\"\\nüìà PH√ÇN T√çCH SIMILARITY DISTRIBUTION:\")\n","\n","    # L·∫•y t·∫•t c·∫£ similarity scores (lo·∫°i b·ªè diagonal)\n","    upper_triangle = np.triu(similarity_matrix, k=1)\n","    non_zero_similarities = upper_triangle[upper_triangle > 0]\n","\n","    print(f\"   üìä Total similarity pairs: {len(non_zero_similarities)}\")\n","    print(f\"   üìà Mean similarity: {np.mean(non_zero_similarities):.4f}\")\n","    print(f\"   üìä Std similarity: {np.std(non_zero_similarities):.4f}\")\n","    print(f\"   üîº Max similarity: {np.max(non_zero_similarities):.4f}\")\n","    print(f\"   üîΩ Min similarity: {np.min(non_zero_similarities):.4f}\")\n","\n","    # Ph√¢n t√≠ch percentiles\n","    percentiles = [25, 50, 75, 90, 95, 99]\n","    print(f\"   üìä Percentiles:\")\n","    for p in percentiles:\n","        val = np.percentile(non_zero_similarities, p)\n","        print(f\"      {p}th: {val:.4f}\")\n","\n","    return {\n","        'mean': np.mean(non_zero_similarities),\n","        'std': np.std(non_zero_similarities),\n","        'max': np.max(non_zero_similarities),\n","        'min': np.min(non_zero_similarities),\n","        'percentiles': {p: np.percentile(non_zero_similarities, p) for p in percentiles}\n","    }\n","\n","def evaluate_cold_start_coverage():\n","    \"\"\"\n","    ƒê√°nh gi√° coverage c·ªßa cold start system\n","    \"\"\"\n","    print(\"\\n‚ùÑÔ∏è ƒê√ÅNH GI√Å COLD START COVERAGE:\")\n","\n","    faculty_codes = [\"cntt\", \"khtn\", \"kinh_te\", \"giao_duc\", \"chinh_tri\", \"van_hoc\"]\n","    coverage_results = {}\n","\n","    for faculty_code in faculty_codes:\n","        result = cold_start_recommendation(faculty_code=faculty_code, top_k=5)\n","\n","        coverage_results[faculty_code] = {\n","            'has_recommendations': result['cold_start_type'] == 'FACULTY_BASED',\n","            'count': result['total_count'],\n","            'category': result.get('matched_category', None)\n","        }\n","\n","        status = \"‚úÖ\" if result['cold_start_type'] == 'FACULTY_BASED' else \"‚ùå\"\n","        print(f\"   {status} {faculty_code}: {result['total_count']} books\")\n","\n","    success_rate = sum(1 for r in coverage_results.values() if r['has_recommendations']) / len(faculty_codes)\n","    print(f\"   üèÜ Faculty Coverage Rate: {success_rate:.1%}\")\n","\n","    return coverage_results\n","\n","def comprehensive_evaluation():\n","    \"\"\"\n","    ƒê√°nh gi√° to√†n di·ªán system\n","    \"\"\"\n","    print(\"üîç COMPREHENSIVE SYSTEM EVALUATION\")\n","    print(\"=\" * 50)\n","\n","    results = {}\n","\n","    # 1. Diversity evaluation\n","    results['diversity'] = evaluate_content_diversity()\n","\n","    # 2. Category precision\n","    results['category_precision'] = evaluate_category_precision()\n","\n","    # 3. Similarity distribution\n","    results['similarity_dist'] = evaluate_similarity_distribution()\n","\n","    # 4. Cold start coverage\n","    results['cold_start'] = evaluate_cold_start_coverage()\n","\n","    return results\n","\n","# Ch·∫°y ƒë√°nh gi√° to√†n di·ªán\n","print(\"\\nüöÄ B·∫ÆT ƒê·∫¶U ƒê√ÅNH GI√Å SYSTEM...\")\n","evaluation_results = comprehensive_evaluation()\n","\n","print(f\"\\nüìä T·ªîNG K·∫æT ƒê√ÅNH GI√Å:\")\n","print(\"=\" * 40)\n","print(f\"‚úÖ Content Diversity: {evaluation_results['diversity']['avg_diversity']:.3f}\")\n","print(f\"‚úÖ Category Precision: {np.mean(list(evaluation_results['category_precision'].values())):.3f}\")\n","print(f\"‚úÖ Mean Similarity: {evaluation_results['similarity_dist']['mean']:.4f}\")\n","print(f\"‚úÖ Cold Start Coverage: {sum(1 for r in evaluation_results['cold_start'].values() if r['has_recommendations'])/6:.1%}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uVqDLG9GbPoh","executionInfo":{"status":"ok","timestamp":1754283180935,"user_tz":-420,"elapsed":867,"user":{"displayName":"Le Nguyen Thai Tuan B2113346","userId":"03563100155966040964"}},"outputId":"21e7ca39-e125-4803-fa4d-a3ed3a375bdc"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["üìä X√ÇY D·ª∞NG FRAMEWORK ƒê√ÅNH GI√Å RECOMMENDATION SYSTEM\n","============================================================\n","\n","üöÄ B·∫ÆT ƒê·∫¶U ƒê√ÅNH GI√Å SYSTEM...\n","üîç COMPREHENSIVE SYSTEM EVALUATION\n","==================================================\n","üé® ƒê√ÅNH GI√Å DIVERSITY:\n","   üìä Average Diversity Score: 1.050\n","   üè∑Ô∏è Average Category Coverage: 1.000\n","   üìà Diversity Range: 1.000 - 1.500\n","\n","üéØ ƒê√ÅNH GI√Å CATEGORY PRECISION:\n","   üìö Tri·∫øt h·ªçc: 1.000\n","   üìö Gi√°o d·ª•c: 1.000\n","   üìö Kinh t·∫ø: 1.000\n","   üìö C√¥ng ngh·ªá th√¥ng tin: 1.000\n","   üìö VƒÉn h·ªçc: 1.000\n","   üìö Khoa h·ªçc t·ª± nhi√™n: 1.000\n","   üèÜ Overall Category Precision: 1.000\n","\n","üìà PH√ÇN T√çCH SIMILARITY DISTRIBUTION:\n","   üìä Total similarity pairs: 7140\n","   üìà Mean similarity: 0.1512\n","   üìä Std similarity: 0.1976\n","   üîº Max similarity: 0.8596\n","   üîΩ Min similarity: 0.0035\n","   üìä Percentiles:\n","      25th: 0.0295\n","      50th: 0.0609\n","      75th: 0.1100\n","      90th: 0.5252\n","      95th: 0.5614\n","      99th: 0.6449\n","\n","‚ùÑÔ∏è ƒê√ÅNH GI√Å COLD START COVERAGE:\n","‚ùÑÔ∏è COLD START RECOMMENDATION\n","üéì Faculty Code: cntt\n","--------------------------------------------------\n","üéì Processing faculty code: 'cntt'\n","‚úÖ Mapped to category: 'C√¥ng ngh·ªá th√¥ng tin'\n","üìö Found 28 books in 'C√¥ng ngh·ªá th√¥ng tin' category\n","‚úÖ Generated 5 recommendations\n","‚úÖ SUCCESS: 5 faculty-based recommendations\n","   ‚úÖ cntt: 5 books\n","‚ùÑÔ∏è COLD START RECOMMENDATION\n","üéì Faculty Code: khtn\n","--------------------------------------------------\n","üéì Processing faculty code: 'khtn'\n","‚úÖ Mapped to category: 'Khoa h·ªçc t·ª± nhi√™n'\n","üìö Found 38 books in 'Khoa h·ªçc t·ª± nhi√™n' category\n","‚úÖ Generated 5 recommendations\n","‚úÖ SUCCESS: 5 faculty-based recommendations\n","   ‚úÖ khtn: 5 books\n","‚ùÑÔ∏è COLD START RECOMMENDATION\n","üéì Faculty Code: kinh_te\n","--------------------------------------------------\n","üéì Processing faculty code: 'kinh_te'\n","‚úÖ Mapped to category: 'Kinh t·∫ø'\n","üìö Found 13 books in 'Kinh t·∫ø' category\n","‚úÖ Generated 5 recommendations\n","‚úÖ SUCCESS: 5 faculty-based recommendations\n","   ‚úÖ kinh_te: 5 books\n","‚ùÑÔ∏è COLD START RECOMMENDATION\n","üéì Faculty Code: giao_duc\n","--------------------------------------------------\n","üéì Processing faculty code: 'giao_duc'\n","‚úÖ Mapped to category: 'Gi√°o d·ª•c'\n","üìö Found 9 books in 'Gi√°o d·ª•c' category\n","‚úÖ Generated 5 recommendations\n","‚úÖ SUCCESS: 5 faculty-based recommendations\n","   ‚úÖ giao_duc: 5 books\n","‚ùÑÔ∏è COLD START RECOMMENDATION\n","üéì Faculty Code: chinh_tri\n","--------------------------------------------------\n","üéì Processing faculty code: 'chinh_tri'\n","‚úÖ Mapped to category: 'Tri·∫øt h·ªçc'\n","üìö Found 13 books in 'Tri·∫øt h·ªçc' category\n","‚úÖ Generated 5 recommendations\n","‚úÖ SUCCESS: 5 faculty-based recommendations\n","   ‚úÖ chinh_tri: 5 books\n","‚ùÑÔ∏è COLD START RECOMMENDATION\n","üéì Faculty Code: van_hoc\n","--------------------------------------------------\n","üéì Processing faculty code: 'van_hoc'\n","‚úÖ Mapped to category: 'VƒÉn h·ªçc'\n","üìö Found 19 books in 'VƒÉn h·ªçc' category\n","‚úÖ Generated 5 recommendations\n","‚úÖ SUCCESS: 5 faculty-based recommendations\n","   ‚úÖ van_hoc: 5 books\n","   üèÜ Faculty Coverage Rate: 100.0%\n","\n","üìä T·ªîNG K·∫æT ƒê√ÅNH GI√Å:\n","========================================\n","‚úÖ Content Diversity: 1.050\n","‚úÖ Category Precision: 1.000\n","‚úÖ Mean Similarity: 0.1512\n","‚úÖ Cold Start Coverage: 100.0%\n"]}]},{"cell_type":"code","source":["# Simple Test Cases using existing functions\n","print(\"üß™ SIMPLE USER TEST CASES\")\n","print(f\"üìÖ Test Date: 2025-08-04 05:01:54 UTC\")\n","print(f\"üë§ Test Admin: Tuan9112\")\n","print(\"=\"*50)\n","\n","# Test 1: Guest User (No faculty, no history)\n","print(\"\\nüë§ TEST 1: GUEST USER\")\n","print(\"-\" * 30)\n","guest_result = cold_start_recommendation(faculty_code=None, top_k=5)\n","print(f\"‚úÖ Type: {guest_result['cold_start_type']}\")\n","print(f\"üìö Count: {guest_result['total_count']}\")\n","print(f\"üí≠ Message: {guest_result['message']}\")\n","\n","# Test 2: New IT Student (Has faculty, no history)\n","print(\"\\nüë§ TEST 2: NEW IT STUDENT\")\n","print(\"-\" * 30)\n","it_result = cold_start_recommendation(faculty_code='cntt', top_k=5)\n","print(f\"‚úÖ Type: {it_result['cold_start_type']}\")\n","print(f\"üìö Count: {it_result['total_count']}\")\n","if it_result['recommendations']:\n","    print(f\"üìñ Sample: {it_result['recommendations'][0]['book_title'][:40]}...\")\n","\n","# Test 3: Economics Student\n","print(\"\\nüë§ TEST 3: ECONOMICS STUDENT\")\n","print(\"-\" * 30)\n","econ_result = cold_start_recommendation(faculty_code='kinh_te', top_k=5)\n","print(f\"‚úÖ Type: {econ_result['cold_start_type']}\")\n","print(f\"üìö Count: {econ_result['total_count']}\")\n","\n","# Test 4: User with History (viewed an IT book)\n","print(\"\\nüë§ TEST 4: USER WITH HISTORY\")\n","print(\"-\" * 30)\n","# User ƒë√£ xem s√°ch \"L·∫≠p tr√¨nh song song\" (index 19)\n","viewed_book_id = index_to_objectid[19]\n","book_info = books_df.iloc[19]\n","print(f\"üìñ Viewed: {book_info['book_title']}\")\n","print(f\"üè∑Ô∏è Category: {book_info['book_category']}\")\n","\n","content_recs = recommend_by_mongodb_id(viewed_book_id, top_k=5)\n","print(f\"‚úÖ Generated: {len(content_recs)} recommendations\")\n","if content_recs:\n","    print(f\"üìö Top rec: {content_recs[0]['book_title'][:40]}...\")\n","    print(f\"üìä Similarity: {content_recs[0]['similarity_score']:.3f}\")\n","\n","# Test 5: User with Cross-domain Interest (viewed Literature book)\n","print(\"\\nüë§ TEST 5: CROSS-DOMAIN USER\")\n","print(\"-\" * 30)\n","# User xem s√°ch vƒÉn h·ªçc\n","lit_book_id = index_to_objectid[67]  # Assuming index 67 is literature\n","lit_book_info = books_df.iloc[67]\n","print(f\"üìñ Viewed: {lit_book_info['book_title']}\")\n","print(f\"üè∑Ô∏è Category: {lit_book_info['book_category']}\")\n","\n","lit_recs = recommend_by_mongodb_id(lit_book_id, top_k=5)\n","print(f\"‚úÖ Generated: {len(lit_recs)} recommendations\")\n","\n","# Test 6: Invalid Faculty Code\n","print(\"\\nüë§ TEST 6: INVALID FACULTY\")\n","print(\"-\" * 30)\n","invalid_result = cold_start_recommendation(faculty_code='y_khoa', top_k=5)\n","print(f\"‚úÖ Type: {invalid_result['cold_start_type']}\")\n","print(f\"üí≠ Message: {invalid_result['message']}\")\n","\n","# Summary\n","print(\"\\nüìä TEST SUMMARY:\")\n","print(\"=\"*25)\n","print(\"‚úÖ Guest User: Show trending (backend handles)\")\n","print(\"‚úÖ New IT Student: 5 CNTT books\")\n","print(\"‚úÖ Economics Student: 5 Kinh t·∫ø books\")\n","print(\"‚úÖ User with History: Content-based recommendations\")\n","print(\"‚úÖ Cross-domain: Literature recommendations\")\n","print(\"‚úÖ Invalid Faculty: Fallback to trending\")\n","\n","print(f\"\\nüéØ ALL USER SCENARIOS COVERED!\")\n","print(f\"üöÄ System ready for production!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fgn5UORvdYvZ","executionInfo":{"status":"ok","timestamp":1754283741984,"user_tz":-420,"elapsed":52,"user":{"displayName":"Le Nguyen Thai Tuan B2113346","userId":"03563100155966040964"}},"outputId":"62a38a58-24e5-4108-a85c-f5c18532b1c4"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["üß™ SIMPLE USER TEST CASES\n","üìÖ Test Date: 2025-08-04 05:01:54 UTC\n","üë§ Test Admin: Tuan9112\n","==================================================\n","\n","üë§ TEST 1: GUEST USER\n","------------------------------\n","‚ùÑÔ∏è COLD START RECOMMENDATION\n","üéì Faculty Code: None\n","--------------------------------------------------\n","‚ùå FALLBACK: No faculty code ‚Üí Show trending\n","‚úÖ Type: SHOW_TRENDING\n","üìö Count: 0\n","üí≠ Message: No faculty information available\n","\n","üë§ TEST 2: NEW IT STUDENT\n","------------------------------\n","‚ùÑÔ∏è COLD START RECOMMENDATION\n","üéì Faculty Code: cntt\n","--------------------------------------------------\n","üéì Processing faculty code: 'cntt'\n","‚úÖ Mapped to category: 'C√¥ng ngh·ªá th√¥ng tin'\n","üìö Found 28 books in 'C√¥ng ngh·ªá th√¥ng tin' category\n","‚úÖ Generated 5 recommendations\n","‚úÖ SUCCESS: 5 faculty-based recommendations\n","‚úÖ Type: FACULTY_BASED\n","üìö Count: 5\n","üìñ Sample: Khai th√°c d·ªØ li·ªáu v·ªõi Python...\n","\n","üë§ TEST 3: ECONOMICS STUDENT\n","------------------------------\n","‚ùÑÔ∏è COLD START RECOMMENDATION\n","üéì Faculty Code: kinh_te\n","--------------------------------------------------\n","üéì Processing faculty code: 'kinh_te'\n","‚úÖ Mapped to category: 'Kinh t·∫ø'\n","üìö Found 13 books in 'Kinh t·∫ø' category\n","‚úÖ Generated 5 recommendations\n","‚úÖ SUCCESS: 5 faculty-based recommendations\n","‚úÖ Type: FACULTY_BASED\n","üìö Count: 5\n","\n","üë§ TEST 4: USER WITH HISTORY\n","------------------------------\n","üìñ Viewed: L·∫≠p tr√¨nh song song\n","üè∑Ô∏è Category: C√¥ng ngh·ªá th√¥ng tin\n","üîç T√¨m s√°ch t∆∞∆°ng t·ª± cho MongoDB ID: 6884a887381cc6a0ba8b7c44\n","üìç Mapped to DataFrame index: 19\n","üìñ S√°ch g·ªëc: L·∫≠p tr√¨nh song song\n","üè∑Ô∏è Category: C√¥ng ngh·ªá th√¥ng tin\n","\n","üèÜ TOP 5 S√ÅCH T∆Ø∆†NG T·ª∞:\n","--------------------------------------------------------------------------------\n"," 1. üìö L·∫≠p tr√¨nh Web\n","    üÜî MongoDB ID: 68405a19771e03946e05a133\n","    üè∑Ô∏è C√¥ng ngh·ªá th√¥ng tin ‚úÖ\n","    üìä Similarity: 0.7753\n","\n"," 2. üìö L·∫≠p tr√¨nh .Net\n","    üÜî MongoDB ID: 6884abd0381cc6a0ba8b7cf9\n","    üè∑Ô∏è C√¥ng ngh·ªá th√¥ng tin ‚úÖ\n","    üìä Similarity: 0.7474\n","\n"," 3. üìö L·∫≠p tr√¨nh cƒÉn b·∫£n v·ªõi ng√¥n ng·ªØ C\n","    üÜî MongoDB ID: 6884be3e6ac42bb47865ea01\n","    üè∑Ô∏è C√¥ng ngh·ªá th√¥ng tin ‚úÖ\n","    üìä Similarity: 0.6867\n","\n"," 4. üìö L·∫≠p tr√¨nh ·ª©ng d·ª•ng m·∫°ng\n","    üÜî MongoDB ID: 68404f0039ed1688cb9d8f7b\n","    üè∑Ô∏è C√¥ng ngh·ªá th√¥ng tin ‚úÖ\n","    üìä Similarity: 0.6747\n","\n"," 5. üìö L·∫≠p tr√¨nh h∆∞·ªõng ƒë·ªëi t∆∞·ª£ng\n","    üÜî MongoDB ID: 6884bcd86ac42bb47865e9cb\n","    üè∑Ô∏è C√¥ng ngh·ªá th√¥ng tin ‚úÖ\n","    üìä Similarity: 0.6397\n","\n","‚úÖ Generated: 5 recommendations\n","üìö Top rec: L·∫≠p tr√¨nh Web...\n","üìä Similarity: 0.775\n","\n","üë§ TEST 5: CROSS-DOMAIN USER\n","------------------------------\n","üìñ Viewed: N·∫•m ƒÉn\n","üè∑Ô∏è Category: Khoa h·ªçc t·ª± nhi√™n\n","üîç T√¨m s√°ch t∆∞∆°ng t·ª± cho MongoDB ID: 688641740304469cbedce3d0\n","üìç Mapped to DataFrame index: 67\n","üìñ S√°ch g·ªëc: N·∫•m ƒÉn\n","üè∑Ô∏è Category: Khoa h·ªçc t·ª± nhi√™n\n","\n","üèÜ TOP 5 S√ÅCH T∆Ø∆†NG T·ª∞:\n","--------------------------------------------------------------------------------\n"," 1. üìö C√¥ng ngh·ªá s·∫£n xu·∫•t r∆∞·ª£u bia v√† n∆∞·ªõc gi·∫£i kh√°t\n","    üÜî MongoDB ID: 68863fe90304469cbedce397\n","    üè∑Ô∏è Khoa h·ªçc t·ª± nhi√™n ‚úÖ\n","    üìä Similarity: 0.6426\n","\n"," 2. üìö Nu√¥i tr·ªìng th·ªßy s·∫£n\n","    üÜî MongoDB ID: 6885b811dbd88552ae1fe917\n","    üè∑Ô∏è Khoa h·ªçc t·ª± nhi√™n ‚úÖ\n","    üìä Similarity: 0.6402\n","\n"," 3. üìö Ng∆∞ nghi·ªáp ƒë·∫°i c∆∞∆°ng\n","    üÜî MongoDB ID: 6885a3cfdbd88552ae1fe677\n","    üè∑Ô∏è Khoa h·ªçc t·ª± nhi√™n ‚úÖ\n","    üìä Similarity: 0.6283\n","\n"," 4. üìö Sinh h·ªçc ·ª©ng d·ª•ng ƒë·∫°i c∆∞∆°ng\n","    üÜî MongoDB ID: 688634380304469cbedce196\n","    üè∑Ô∏è Khoa h·ªçc t·ª± nhi√™n ‚úÖ\n","    üìä Similarity: 0.6219\n","\n"," 5. üìö Gi√°o tr√¨nh X·ª≠ l√Ω sau thu ho·∫°ch v√† ch·∫ø bi·∫øn s·∫£n ph·∫©\n","    üÜî MongoDB ID: 6885aa00dbd88552ae1fe783\n","    üè∑Ô∏è Khoa h·ªçc t·ª± nhi√™n ‚úÖ\n","    üìä Similarity: 0.6185\n","\n","‚úÖ Generated: 5 recommendations\n","\n","üë§ TEST 6: INVALID FACULTY\n","------------------------------\n","‚ùÑÔ∏è COLD START RECOMMENDATION\n","üéì Faculty Code: y_khoa\n","--------------------------------------------------\n","üéì Processing faculty code: 'y_khoa'\n","‚ùå Faculty code 'y_khoa' not found in mapping\n","üìã Available codes: ['cntt', 'khtn', 'kinh_te', 'giao_duc', 'chinh_tri', 'van_hoc']\n","‚ùå FALLBACK: No books for faculty 'y_khoa' ‚Üí Show trending\n","‚úÖ Type: SHOW_TRENDING\n","üí≠ Message: No books available for faculty: y_khoa\n","\n","üìä TEST SUMMARY:\n","=========================\n","‚úÖ Guest User: Show trending (backend handles)\n","‚úÖ New IT Student: 5 CNTT books\n","‚úÖ Economics Student: 5 Kinh t·∫ø books\n","‚úÖ User with History: Content-based recommendations\n","‚úÖ Cross-domain: Literature recommendations\n","‚úÖ Invalid Faculty: Fallback to trending\n","\n","üéØ ALL USER SCENARIOS COVERED!\n","üöÄ System ready for production!\n"]}]},{"cell_type":"code","source":["# Cell 12: Save Model to /content/drive/MyDrive/Ebooks - FIXED VERSION\n","import pickle\n","import json\n","import pandas as pd\n","import numpy as np\n","import os\n","\n","print(\"üíæ SAVING MODEL TO /content/drive/MyDrive/Ebooks\")\n","print(f\"üìÖ Current Date and Time: 2025-08-04 05:19:28 UTC\")\n","print(f\"üë§ Current User's Login: Tuan9112\")\n","print(\"=\"*65)\n","\n","# ƒê∆∞·ªùng d·∫´n ch√≠nh x√°c cho Google Colab\n","model_save_path = \"/content/drive/MyDrive/Ebooks\"\n","\n","# Ki·ªÉm tra v√† t·∫°o th∆∞ m·ª•c n·∫øu c·∫ßn\n","print(f\"üìç Target Directory: {model_save_path}\")\n","if not os.path.exists(model_save_path):\n","    print(\"üîß Creating directory...\")\n","    os.makedirs(model_save_path, exist_ok=True)\n","\n","print(f\"‚úÖ Directory exists: {os.path.exists(model_save_path)}\")\n","print(f\"‚úÖ Directory writable: {os.access(model_save_path, os.W_OK)}\")\n","\n","def save_model_to_google_drive():\n","    \"\"\"\n","    L∆∞u model v√†o Google Drive Ebooks folder\n","    \"\"\"\n","    print(f\"\\nüíæ SAVING MODEL FILES TO GOOGLE DRIVE...\")\n","\n","    saved_files = []\n","\n","    try:\n","        # 1. Save similarity matrix\n","        similarity_file = os.path.join(model_save_path, 'similarity_matrix.pkl')\n","        with open(similarity_file, 'wb') as f:\n","            pickle.dump(similarity_matrix, f)\n","        saved_files.append('similarity_matrix.pkl')\n","        print(f\"   ‚úÖ {similarity_file}\")\n","\n","        # 2. Save index to ObjectId mapping\n","        index_mapping_file = os.path.join(model_save_path, 'index_to_objectid.json')\n","        json_mapping = {str(k): str(v) for k, v in index_to_objectid.items()}\n","        with open(index_mapping_file, 'w') as f:\n","            json.dump(json_mapping, f, indent=2)\n","        saved_files.append('index_to_objectid.json')\n","        print(f\"   ‚úÖ {index_mapping_file}\")\n","\n","        # 3. Save ObjectId to index mapping (reverse)\n","        objectid_mapping_file = os.path.join(model_save_path, 'objectid_to_index.json')\n","        objectid_to_index = {str(v): k for k, v in index_to_objectid.items()}\n","        with open(objectid_mapping_file, 'w') as f:\n","            json.dump(objectid_to_index, f, indent=2)\n","        saved_files.append('objectid_to_index.json')\n","        print(f\"   ‚úÖ {objectid_mapping_file}\")\n","\n","        # 4. Save books dataframe\n","        books_pkl_file = os.path.join(model_save_path, 'books_model_data.pkl')\n","        books_df.to_pickle(books_pkl_file)\n","        saved_files.append('books_model_data.pkl')\n","        print(f\"   ‚úÖ {books_pkl_file}\")\n","\n","        # 5. Save faculty mapping\n","        faculty_file = os.path.join(model_save_path, 'faculty_mapping.json')\n","        faculty_mapping = {\n","            \"cntt\": \"C√¥ng ngh·ªá th√¥ng tin\",\n","            \"khtn\": \"Khoa h·ªçc t·ª± nhi√™n\",\n","            \"kinh_te\": \"Kinh t·∫ø\",\n","            \"giao_duc\": \"Gi√°o d·ª•c\",\n","            \"chinh_tri\": \"Tri·∫øt h·ªçc\",\n","            \"van_hoc\": \"VƒÉn h·ªçc\"\n","        }\n","\n","        with open(faculty_file, 'w', encoding='utf-8') as f:\n","            json.dump(faculty_mapping, f, ensure_ascii=False, indent=2)\n","        saved_files.append('faculty_mapping.json')\n","        print(f\"   ‚úÖ {faculty_file}\")\n","\n","        # 6. Save model metadata\n","        metadata_file = os.path.join(model_save_path, 'model_metadata.json')\n","        metadata = {\n","            \"model_info\": {\n","                \"type\": \"content_based_recommendation\",\n","                \"version\": \"1.0.0\",\n","                \"created_date\": \"2025-08-04 05:19:28\",\n","                \"created_by\": \"Tuan9112\",\n","                \"location\": \"/content/drive/MyDrive/Ebooks\"\n","            },\n","            \"data_stats\": {\n","                \"total_books\": len(books_df),\n","                \"similarity_matrix_shape\": list(similarity_matrix.shape),\n","                \"categories\": books_df['book_category'].unique().tolist(),\n","                \"document_types\": books_df['book_document_type'].unique().tolist()\n","            },\n","            \"technical_details\": {\n","                \"feature_engineering\": \"TF-IDF on combined features\",\n","                \"similarity_metric\": \"cosine_similarity\",\n","                \"cold_start_strategy\": \"Faculty-based filtering\"\n","            },\n","            \"performance\": {\n","                \"content_diversity\": 1.050,\n","                \"category_precision\": 1.000,\n","                \"mean_similarity\": 0.1512\n","            }\n","        }\n","\n","        with open(metadata_file, 'w', encoding='utf-8') as f:\n","            json.dump(metadata, f, ensure_ascii=False, indent=2)\n","        saved_files.append('model_metadata.json')\n","        print(f\"   ‚úÖ {metadata_file}\")\n","\n","        return saved_files\n","\n","    except Exception as e:\n","        print(f\"   ‚ùå Error saving files: {str(e)}\")\n","        return []\n","\n","def create_deployment_guide():\n","    \"\"\"\n","    T·∫°o deployment guide ri√™ng bi·ªát\n","    \"\"\"\n","    print(\"üìñ Creating deployment guide...\")\n","\n","    guide_content = [\n","        \"# Book Recommendation Model - Deployment Guide\",\n","        \"\",\n","        \"## Model Information\",\n","        \"- Created: 2025-08-04 05:19:28 UTC\",\n","        \"- Created by: Tuan9112\",\n","        \"- Type: Content-based Recommendation System\",\n","        \"- Version: 1.0.0\",\n","        \"\",\n","        \"## Production Files\",\n","        \"1. similarity_matrix.pkl - Main recommendation engine\",\n","        \"2. index_to_objectid.json - Maps index to MongoDB ObjectId\",\n","        \"3. objectid_to_index.json - Maps ObjectId to index\",\n","        \"4. books_model_data.pkl - Books dataset\",\n","        \"5. faculty_mapping.json - Faculty mappings\",\n","        \"6. model_metadata.json - Model information\",\n","        \"\",\n","        \"## Usage Example\",\n","        \"```python\",\n","        \"import pickle\",\n","        \"import json\",\n","        \"\",\n","        \"# Load model\",\n","        \"with open('similarity_matrix.pkl', 'rb') as f:\",\n","        \"    similarity_matrix = pickle.load(f)\",\n","        \"\",\n","        \"# Load mappings\",\n","        \"with open('objectid_to_index.json', 'r') as f:\",\n","        \"    objectid_to_index = json.load(f)\",\n","        \"```\",\n","        \"\",\n","        \"## Performance\",\n","        \"- Content Diversity: 1.050\",\n","        \"- Category Precision: 1.000\",\n","        \"- Cold Start Coverage: 100%\",\n","        \"\",\n","        \"Ready for production deployment!\"\n","    ]\n","\n","    guide_file = os.path.join(model_save_path, 'DEPLOYMENT_GUIDE.txt')\n","    with open(guide_file, 'w', encoding='utf-8') as f:\n","        f.write('\\n'.join(guide_content))\n","\n","    print(f\"   ‚úÖ {guide_file}\")\n","    return 'DEPLOYMENT_GUIDE.txt'\n","\n","def verify_saved_files():\n","    \"\"\"\n","    Verify files ƒë√£ l∆∞u\n","    \"\"\"\n","    print(f\"\\nüîç VERIFYING SAVED FILES...\")\n","\n","    expected_files = [\n","        'similarity_matrix.pkl',\n","        'index_to_objectid.json',\n","        'objectid_to_index.json',\n","        'books_model_data.pkl',\n","        'faculty_mapping.json',\n","        'model_metadata.json',\n","        'DEPLOYMENT_GUIDE.txt'\n","    ]\n","\n","    verified_count = 0\n","    total_size = 0\n","\n","    for file in expected_files:\n","        file_path = os.path.join(model_save_path, file)\n","        if os.path.exists(file_path):\n","            size = os.path.getsize(file_path)\n","            total_size += size\n","            verified_count += 1\n","            print(f\"   ‚úÖ {file} ({size:,} bytes)\")\n","        else:\n","            print(f\"   ‚ùå {file} - NOT FOUND\")\n","\n","    print(f\"\\nüìä SUMMARY:\")\n","    print(f\"   Files verified: {verified_count}/{len(expected_files)}\")\n","    print(f\"   Total size: {total_size:,} bytes ({total_size/1024/1024:.2f} MB)\")\n","\n","    return verified_count == len(expected_files)\n","\n","def test_model_loading():\n","    \"\"\"\n","    Test loading model t·ª´ saved files\n","    \"\"\"\n","    print(f\"\\nüß™ TESTING MODEL LOADING...\")\n","\n","    try:\n","        # Test similarity matrix\n","        similarity_file = os.path.join(model_save_path, 'similarity_matrix.pkl')\n","        with open(similarity_file, 'rb') as f:\n","            test_similarity = pickle.load(f)\n","        print(f\"   ‚úÖ Similarity matrix: {test_similarity.shape}\")\n","\n","        # Test mappings\n","        mapping_file = os.path.join(model_save_path, 'index_to_objectid.json')\n","        with open(mapping_file, 'r') as f:\n","            test_mapping = json.load(f)\n","        print(f\"   ‚úÖ Mapping: {len(test_mapping)} entries\")\n","\n","        # Test functionality\n","        test_similarities = test_similarity[0]\n","        top_similar = sorted(range(len(test_similarities)),\n","                           key=lambda i: test_similarities[i], reverse=True)[1:6]\n","        print(f\"   ‚úÖ Recommendations: {len(top_similar)} generated\")\n","\n","        return True\n","\n","    except Exception as e:\n","        print(f\"   ‚ùå Test failed: {str(e)}\")\n","        return False\n","\n","# Execute save process\n","try:\n","    print(\"üöÄ STARTING SAVE PROCESS...\")\n","\n","    # Save main model files\n","    saved_files = save_model_to_google_drive()\n","\n","    if saved_files:\n","        print(f\"\\n‚úÖ MAIN FILES SAVED!\")\n","\n","        # Create deployment guide\n","        guide_file = create_deployment_guide()\n","        saved_files.append(guide_file)\n","\n","        # Verify all files\n","        verification_success = verify_saved_files()\n","\n","        if verification_success:\n","            print(f\"\\nüîç VERIFICATION: ‚úÖ PASSED\")\n","\n","            # Test loading\n","            test_success = test_model_loading()\n","\n","            if test_success:\n","                print(f\"\\nüß™ FUNCTIONALITY TEST: ‚úÖ PASSED\")\n","                print(f\"\\nüéâ MODEL DEPLOYMENT COMPLETE!\")\n","                print(f\"\\nüìç LOCATION: {model_save_path}\")\n","                print(f\"üìÅ FILES READY: {len(saved_files)}\")\n","                print(f\"\\nüöÄ READY FOR API DEVELOPMENT!\")\n","            else:\n","                print(f\"\\n‚ùå FUNCTIONALITY TEST FAILED\")\n","        else:\n","            print(f\"\\n‚ùå VERIFICATION FAILED\")\n","    else:\n","        print(f\"\\n‚ùå SAVE FAILED\")\n","\n","except Exception as e:\n","    print(f\"\\nüö® ERROR: {str(e)}\")\n","    print(\"üîß Please check variables and try again\")\n","\n","print(f\"\\nüìç MODEL SAVED TO: /content/drive/MyDrive/Ebooks\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UOf8J0yIf1Iv","executionInfo":{"status":"ok","timestamp":1754284884739,"user_tz":-420,"elapsed":159,"user":{"displayName":"Le Nguyen Thai Tuan B2113346","userId":"03563100155966040964"}},"outputId":"90ca8741-d7ef-4133-f588-ee8bb6f3ae24"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["üíæ SAVING MODEL TO /content/drive/MyDrive/Ebooks\n","üìÖ Current Date and Time: 2025-08-04 05:19:28 UTC\n","üë§ Current User's Login: Tuan9112\n","=================================================================\n","üìç Target Directory: /content/drive/MyDrive/Ebooks\n","‚úÖ Directory exists: True\n","‚úÖ Directory writable: True\n","üöÄ STARTING SAVE PROCESS...\n","\n","üíæ SAVING MODEL FILES TO GOOGLE DRIVE...\n","   ‚úÖ /content/drive/MyDrive/Ebooks/similarity_matrix.pkl\n","   ‚úÖ /content/drive/MyDrive/Ebooks/index_to_objectid.json\n","   ‚úÖ /content/drive/MyDrive/Ebooks/objectid_to_index.json\n","   ‚úÖ /content/drive/MyDrive/Ebooks/books_model_data.pkl\n","   ‚úÖ /content/drive/MyDrive/Ebooks/faculty_mapping.json\n","   ‚úÖ /content/drive/MyDrive/Ebooks/model_metadata.json\n","\n","‚úÖ MAIN FILES SAVED!\n","üìñ Creating deployment guide...\n","   ‚úÖ /content/drive/MyDrive/Ebooks/DEPLOYMENT_GUIDE.txt\n","\n","üîç VERIFYING SAVED FILES...\n","   ‚úÖ similarity_matrix.pkl (115,362 bytes)\n","   ‚úÖ index_to_objectid.json (4,332 bytes)\n","   ‚úÖ objectid_to_index.json (4,092 bytes)\n","   ‚úÖ books_model_data.pkl (762,712 bytes)\n","   ‚úÖ faculty_mapping.json (189 bytes)\n","   ‚úÖ model_metadata.json (861 bytes)\n","   ‚úÖ DEPLOYMENT_GUIDE.txt (890 bytes)\n","\n","üìä SUMMARY:\n","   Files verified: 7/7\n","   Total size: 888,438 bytes (0.85 MB)\n","\n","üîç VERIFICATION: ‚úÖ PASSED\n","\n","üß™ TESTING MODEL LOADING...\n","   ‚úÖ Similarity matrix: (120, 120)\n","   ‚úÖ Mapping: 120 entries\n","   ‚úÖ Recommendations: 5 generated\n","\n","üß™ FUNCTIONALITY TEST: ‚úÖ PASSED\n","\n","üéâ MODEL DEPLOYMENT COMPLETE!\n","\n","üìç LOCATION: /content/drive/MyDrive/Ebooks\n","üìÅ FILES READY: 7\n","\n","üöÄ READY FOR API DEVELOPMENT!\n","\n","üìç MODEL SAVED TO: /content/drive/MyDrive/Ebooks\n"]}]},{"cell_type":"code","source":["print(\"\\nüéØ RANKING C√ÅC H√ÄM THEO M·ª®C ƒê·ªò QUAN TR·ªåNG\")\n","print(\"=\"*50)\n","\n","critical_functions = [\n","    (\"‚≠ê‚≠ê‚≠ê CRITICAL\", \"create_combined_features()\", \"T·∫°o features t·ª´ text\"),\n","    (\"‚≠ê‚≠ê‚≠ê CRITICAL\", \"cosine_similarity()\", \"T√≠nh ƒë·ªô t∆∞∆°ng ƒë·ªìng\"),\n","    (\"‚≠ê‚≠ê‚≠ê CRITICAL\", \"get_recommendations_by_objectid()\", \"Engine ch√≠nh\"),\n","    (\"‚≠ê‚≠ê IMPORTANT\", \"TfidfVectorizer\", \"Chuy·ªÉn text‚Üínumbers\"),\n","    (\"‚≠ê‚≠ê IMPORTANT\", \"index_to_objectid mapping\", \"K·∫øt n·ªëi v·ªõi database\"),\n","    (\"‚≠ê HELPFUL\", \"get_recommendations_by_faculty()\", \"Cold start\"),\n","    (\"‚≠ê HELPFUL\", \"evaluate_model()\", \"ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng\")\n","]\n","\n","for importance, function, description in critical_functions:\n","    print(f\"   {importance}: {function}\")\n","    print(f\"      ‚Üí {description}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cXzlBlrnil8z","executionInfo":{"status":"ok","timestamp":1754285106475,"user_tz":-420,"elapsed":29,"user":{"displayName":"Le Nguyen Thai Tuan B2113346","userId":"03563100155966040964"}},"outputId":"60bbf4e1-ee24-45eb-9c88-843f65774b29"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","üéØ RANKING C√ÅC H√ÄM THEO M·ª®C ƒê·ªò QUAN TR·ªåNG\n","==================================================\n","   ‚≠ê‚≠ê‚≠ê CRITICAL: create_combined_features()\n","      ‚Üí T·∫°o features t·ª´ text\n","   ‚≠ê‚≠ê‚≠ê CRITICAL: cosine_similarity()\n","      ‚Üí T√≠nh ƒë·ªô t∆∞∆°ng ƒë·ªìng\n","   ‚≠ê‚≠ê‚≠ê CRITICAL: get_recommendations_by_objectid()\n","      ‚Üí Engine ch√≠nh\n","   ‚≠ê‚≠ê IMPORTANT: TfidfVectorizer\n","      ‚Üí Chuy·ªÉn text‚Üínumbers\n","   ‚≠ê‚≠ê IMPORTANT: index_to_objectid mapping\n","      ‚Üí K·∫øt n·ªëi v·ªõi database\n","   ‚≠ê HELPFUL: get_recommendations_by_faculty()\n","      ‚Üí Cold start\n","   ‚≠ê HELPFUL: evaluate_model()\n","      ‚Üí ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng\n"]}]}]}