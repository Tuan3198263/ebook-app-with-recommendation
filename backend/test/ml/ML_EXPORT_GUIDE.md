# Machine Learning Data Export Guide (Optimized)

## ğŸ“ Cáº¥u trÃºc thÆ° má»¥c

```
backend/test/ml/
â”œâ”€â”€ exportCollaborativeFilteringData.js  # Export dá»¯ liá»‡u thÃ nh CSV (simplified)
â”œâ”€â”€ exports/                             # ThÆ° má»¥c chá»©a file CSV
â”œâ”€â”€ IMPLICIT_RATING_GUIDE.md             # HÆ°á»›ng dáº«n rating system
â””â”€â”€ ML_EXPORT_GUIDE.md                   # File hÆ°á»›ng dáº«n nÃ y
```

## ğŸ”§ Export Command

### Export dá»¯ liá»‡u cho Machine Learning

```bash
npm run ml:export-cf
```

**Chá»©c nÄƒng:**

- âš¡ Sá»­ dá»¥ng maxInteractionScore trá»±c tiáº¿p lÃ m rating
- ğŸ“¤ Export 4 file CSV tá»‘i Æ°u
- ğŸ“Š Generate summary statistics
- ğŸ“ Táº¡o documentation file
- ğŸ§¹ Loáº¡i bá» cÃ¡c trÆ°á»ng khÃ´ng cáº§n thiáº¿t

## ğŸ“Š Files Ä‘Æ°á»£c export (Optimized)

### **1. collaborative*filtering_data*[timestamp].csv** â­ MAIN DATASET

**Purpose**: Dá»¯ liá»‡u chÃ­nh cho hybrid ML models

**Columns (8 trÆ°á»ng):**

- `user_id`: ID ngÆ°á»i dÃ¹ng
- `book_id`: ID sÃ¡ch
- `rating`: maxInteractionScore (1-5) - RATING CHÃNH
- `user_faculty`: Khoa cá»§a user (faculty-aware CF)
- `book_title`: TÃªn sÃ¡ch (content-based)
- `book_description`: MÃ´ táº£ sÃ¡ch (content-based)
- `book_category`: Danh má»¥c sÃ¡ch (content-based)
- `book_document_type`: Loáº¡i tÃ i liá»‡u (content-based)

**Sá»­ dá»¥ng cho**: Hybrid CF, Neural CF, Matrix Factorization

### **2. cf*matrix_simple*[timestamp].csv** âš¡ BASIC CF

**Purpose**: Ma tráº­n Ä‘Æ¡n giáº£n cho thuáº­t toÃ¡n CF cÆ¡ báº£n

**Columns (3 trÆ°á»ng):**

- `user_id`: ID ngÆ°á»i dÃ¹ng
- `book_id`: ID sÃ¡ch
- `rating`: maxInteractionScore (1-5)

**Sá»­ dá»¥ng cho**: User-based CF, Item-based CF, SVD

### **3. book*profiles*[timestamp].csv** ğŸ“š CONTENT FEATURES

**Purpose**: ThÃ´ng tin sÃ¡ch cho content-based filtering

**Columns:**

- `book_id`: ID sÃ¡ch
- `title`: TÃªn sÃ¡ch (cleaned)
- `description`: MÃ´ táº£ sÃ¡ch (cleaned)
- `category`: Danh má»¥c
- `document_type`: Loáº¡i tÃ i liá»‡u
- `interaction_count`: Sá»‘ lÆ°á»£ng tÆ°Æ¡ng tÃ¡c (popularity)
- `avg_rating`: Rating trung bÃ¬nh (quality)

**Sá»­ dá»¥ng cho**: Content-based filtering, popularity analysis

### **4. export*summary*[timestamp].txt** ğŸ“‹ DOCUMENTATION

**Purpose**: Thá»‘ng kÃª vÃ  metadata

**Content:**

- Dataset statistics
- Rating calculation method
- File structure documentation
- Next steps guide

## â­ Rating Calculation (Simplified)

**NEW APPROACH:**

```
rating = maxInteractionScore (direct from frontend)
```

**Loáº¡i bá»:**

- âŒ Combined score vá»›i weighted formula
- âŒ Duration/frequency/recency calculations
- âŒ Complex normalization
- âŒ Multiple rating variants

**Frontend Rating Logic:**

```javascript
// BookDetail.vue - Simplified
function calculateMaxInteractionScore() {
  let score = 1; // Base score

  // Time bonus: +1 per 30s (max +3)
  score += Math.min(Math.floor(readingTime / 30), 3);

  // Scroll bonus: +1 if >50%, +2 if >80%
  if (scrollDepth > 80) score += 2;
  else if (scrollDepth > 50) score += 1;

  // Deep engagement: +1 if >2min + >70% scroll
  if (readingTime > 120 && scrollDepth > 70) score += 1;

  return Math.min(score, 5); // Cap at 5
}
```

**Benefits:**

- âœ… Frontend-Backend consistency
- âœ… Simplified export logic
- âœ… Faster processing
- âœ… Easier to understand and debug

## ğŸ¯ ML Model Strategies (Updated)

### **1. Basic Collaborative Filtering**

```python
# Load simplified matrix
df = pd.read_csv('cf_matrix_simple_*.csv')

# Create user-item matrix
matrix = df.pivot(index='user_id', columns='book_id', values='rating')

# Calculate similarity
from sklearn.metrics.pairwise import cosine_similarity
user_similarity = cosine_similarity(matrix.fillna(0))
```

### **2. Hybrid Recommendations**

```python
# Load main dataset with content features
df = pd.read_csv('collaborative_filtering_data_*.csv')

# Faculty-aware CF
faculty_preferences = df.groupby(['user_faculty', 'book_category'])['rating'].mean()

# Content-based similarity
from sklearn.feature_extraction.text import TfidfVectorizer
tfidf = TfidfVectorizer(stop_words='english', max_features=1000)
book_features = tfidf.fit_transform(df['book_description'].fillna(''))
```

### **3. Matrix Factorization**

```python
# Using Surprise library
from surprise import Dataset, Reader, SVD
reader = Reader(rating_scale=(1, 5))
data = Dataset.load_from_df(df[['user_id', 'book_id', 'rating']], reader)

# Train SVD model
svd = SVD(n_factors=50, random_state=42)
```

### **4. Neural Collaborative Filtering**

```python
# Using TensorFlow/Keras
import tensorflow as tf

# Embedding layers for users and books
user_embedding = tf.keras.layers.Embedding(n_users, 50)
book_embedding = tf.keras.layers.Embedding(n_books, 50)

# Additional features: faculty, category as categorical inputs
```

## ğŸ“ˆ Expected Performance

### **Optimized Metrics:**

- **Matrix Density**: 1-3% (standard for rec systems)
- **User Coverage**: 90%+ (most users have interactions)
- **Item Coverage**: 70%+ (most books have interactions)
- **Average Rating**: 2.8-3.5 (realistic range)
- **Rating Distribution**: Balanced across 1-5 scale

### **Quality Indicators:**

- âœ… No duplicate user-item pairs
- âœ… Rating values strictly 1-5 (integer)
- âœ… All required fields populated
- âœ… Faculty distribution balanced
- âœ… Category distribution realistic

## ğŸš€ Optimized Workflow

### **Phase 1: Data Preparation**

```bash
# Generate test data
npm run test:create-users
npm run test:create-interactions

# Export for ML
npm run ml:export-cf
```

### **Phase 2: ML Development** (Google Colab)

1. **Upload CSV files** to Colab
2. **Load main dataset**: `pd.read_csv('collaborative_filtering_data_*.csv')`
3. **Basic EDA**: Check data quality, distributions
4. **Train models**: CF, Matrix Factorization, Hybrid
5. **Evaluate**: RMSE, Precision@K, Diversity metrics

### **Phase 3: Model Selection**

1. **Compare algorithms**: User-based vs Item-based vs SVD
2. **Hyperparameter tuning**: Grid search optimal parameters
3. **Cross-validation**: Ensure robust performance
4. **A/B testing setup**: Compare against existing system

### **Phase 4: Production Integration**

1. **Export model**: Save trained model (pickle/joblib)
2. **API integration**: Create recommendation endpoint
3. **Real-time inference**: Fast recommendation serving
4. **Monitoring**: Track click-through rates, conversions

## ï¿½ Advanced Techniques (Simplified)

### **1. Faculty-aware Recommendations:**

```python
# Calculate faculty bias directly from main data
faculty_bias = df.groupby(['user_faculty', 'book_category'])['rating'].agg(['mean', 'count'])

# Apply bias to recommendations
def faculty_weighted_score(user_faculty, book_category, base_score):
    bias = faculty_bias.loc[(user_faculty, book_category), 'mean']
    return 0.8 * base_score + 0.2 * bias
```

### **2. Cold Start Solutions:**

```python
# New users: use faculty-based recommendations
def recommend_for_new_user(user_faculty):
    popular_in_faculty = df[df['user_faculty'] == user_faculty]\
        .groupby('book_id')['rating'].mean().sort_values(ascending=False)
    return popular_in_faculty.head(10)

# New books: use category-based recommendations
def recommend_new_book(book_category):
    category_lovers = df[df['book_category'] == book_category]['user_id'].unique()
    return category_lovers
```

### **3. Content Enhancement:**

```python
# Enhance book profiles with additional features
books = pd.read_csv('book_profiles_*.csv')

# TF-IDF on descriptions
from sklearn.feature_extraction.text import TfidfVectorizer
tfidf = TfidfVectorizer(max_features=500, stop_words='english')
book_content_features = tfidf.fit_transform(books['description'])

# Combine with CF scores
hybrid_score = 0.7 * cf_score + 0.3 * content_similarity_score
```

## ğŸ” Quality Checks (Streamlined)

### **Data Validation:**

- âœ… Rating range: 1-5 (integer)
- âœ… No missing user_id/book_id
- âœ… Faculty distribution: ~16.7% per faculty (6 faculties)
- âœ… Category distribution: Balanced across book categories
- âœ… Interaction minimum: Each user has >= 5 interactions

### **Model Validation:**

- âœ… RMSE < 1.0 (good prediction accuracy)
- âœ… Coverage > 70% (diverse recommendations)
- âœ… Precision@10 > 0.3 (relevant recommendations)
- âœ… Faculty bias reasonable (not extreme)
- âœ… No cold start issues

## ğŸ“Š Success Metrics

### **Offline Evaluation:**

- **RMSE**: < 0.8 (excellent), < 1.0 (good)
- **Precision@K**: > 0.3 (K=10)
- **Recall@K**: > 0.2 (K=10)
- **Coverage**: > 70% of books recommended
- **Diversity**: Intra-list diversity > 0.7

### **Online Evaluation:**

- **Click-through Rate**: Improvement over baseline
- **Conversion Rate**: Downloads/purchases increase
- **Session Duration**: Users engage longer
- **Return Rate**: Users come back more frequently

Dá»¯ liá»‡u export Ä‘Ã£ Ä‘Æ°á»£c tá»‘i Æ°u hoÃ¡ cho mÃ¡y há»c hiá»‡u quáº£! ğŸ¯
